{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "EDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icarogga/Projeto-Imersao-de-Dados-Alura-3/blob/main/EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmNsHjz2MeZA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvzdrTdDMeZD"
      },
      "source": [
        "## Carregando os dados dos resultados dos experimentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07X0F721MeZE"
      },
      "source": [
        "dados_resultados = pd.read_csv('https://www.dropbox.com/s/g6o6b2x77532q0c/dados_resultados.csv?dl=1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiHwBLtYMeZE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "8679a277-95d4-4a5a-918f-9e1f234e98bf"
      },
      "source": [
        "dados_resultados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>5-alpha_reductase_inhibitor</th>\n",
              "      <th>11-beta-hsd1_inhibitor</th>\n",
              "      <th>acat_inhibitor</th>\n",
              "      <th>acetylcholine_receptor_agonist</th>\n",
              "      <th>acetylcholine_receptor_antagonist</th>\n",
              "      <th>acetylcholinesterase_inhibitor</th>\n",
              "      <th>adenosine_receptor_agonist</th>\n",
              "      <th>adenosine_receptor_antagonist</th>\n",
              "      <th>adenylyl_cyclase_activator</th>\n",
              "      <th>adrenergic_receptor_agonist</th>\n",
              "      <th>adrenergic_receptor_antagonist</th>\n",
              "      <th>akt_inhibitor</th>\n",
              "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
              "      <th>alk_inhibitor</th>\n",
              "      <th>ampk_activator</th>\n",
              "      <th>analgesic</th>\n",
              "      <th>androgen_receptor_agonist</th>\n",
              "      <th>androgen_receptor_antagonist</th>\n",
              "      <th>anesthetic_-_local</th>\n",
              "      <th>angiogenesis_inhibitor</th>\n",
              "      <th>angiotensin_receptor_antagonist</th>\n",
              "      <th>anti-inflammatory</th>\n",
              "      <th>antiarrhythmic</th>\n",
              "      <th>antibiotic</th>\n",
              "      <th>anticonvulsant</th>\n",
              "      <th>antifungal</th>\n",
              "      <th>antihistamine</th>\n",
              "      <th>antimalarial</th>\n",
              "      <th>antioxidant</th>\n",
              "      <th>antiprotozoal</th>\n",
              "      <th>antiviral</th>\n",
              "      <th>apoptosis_stimulant</th>\n",
              "      <th>aromatase_inhibitor</th>\n",
              "      <th>atm_kinase_inhibitor</th>\n",
              "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
              "      <th>atp_synthase_inhibitor</th>\n",
              "      <th>atpase_inhibitor</th>\n",
              "      <th>atr_kinase_inhibitor</th>\n",
              "      <th>aurora_kinase_inhibitor</th>\n",
              "      <th>...</th>\n",
              "      <th>protein_synthesis_inhibitor</th>\n",
              "      <th>protein_tyrosine_kinase_inhibitor</th>\n",
              "      <th>radiopaque_medium</th>\n",
              "      <th>raf_inhibitor</th>\n",
              "      <th>ras_gtpase_inhibitor</th>\n",
              "      <th>retinoid_receptor_agonist</th>\n",
              "      <th>retinoid_receptor_antagonist</th>\n",
              "      <th>rho_associated_kinase_inhibitor</th>\n",
              "      <th>ribonucleoside_reductase_inhibitor</th>\n",
              "      <th>rna_polymerase_inhibitor</th>\n",
              "      <th>serotonin_receptor_agonist</th>\n",
              "      <th>serotonin_receptor_antagonist</th>\n",
              "      <th>serotonin_reuptake_inhibitor</th>\n",
              "      <th>sigma_receptor_agonist</th>\n",
              "      <th>sigma_receptor_antagonist</th>\n",
              "      <th>smoothened_receptor_antagonist</th>\n",
              "      <th>sodium_channel_inhibitor</th>\n",
              "      <th>sphingosine_receptor_agonist</th>\n",
              "      <th>src_inhibitor</th>\n",
              "      <th>steroid</th>\n",
              "      <th>syk_inhibitor</th>\n",
              "      <th>tachykinin_antagonist</th>\n",
              "      <th>tgf-beta_receptor_inhibitor</th>\n",
              "      <th>thrombin_inhibitor</th>\n",
              "      <th>thymidylate_synthase_inhibitor</th>\n",
              "      <th>tlr_agonist</th>\n",
              "      <th>tlr_antagonist</th>\n",
              "      <th>tnf_inhibitor</th>\n",
              "      <th>topoisomerase_inhibitor</th>\n",
              "      <th>transient_receptor_potential_channel_antagonist</th>\n",
              "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
              "      <th>trpv_agonist</th>\n",
              "      <th>trpv_antagonist</th>\n",
              "      <th>tubulin_inhibitor</th>\n",
              "      <th>tyrosine_kinase_inhibitor</th>\n",
              "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
              "      <th>vegfr_inhibitor</th>\n",
              "      <th>vitamin_b</th>\n",
              "      <th>vitamin_d_receptor_agonist</th>\n",
              "      <th>wnt_inhibitor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 207 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...  wnt_inhibitor\n",
              "0  id_000644bb2  ...              0\n",
              "1  id_000779bfc  ...              0\n",
              "2  id_000a6266a  ...              0\n",
              "3  id_0015fd391  ...              0\n",
              "4  id_001626bd3  ...              0\n",
              "\n",
              "[5 rows x 207 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG2jO-EPMeZF"
      },
      "source": [
        "#### Na função abaixo podemos entender um pouco sobre a distribuição dos nossos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxIRwc_aMeZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "adebe4ff-2d4a-4e08-8621-1cdf0dfeb082"
      },
      "source": [
        "dados_resultados.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>5-alpha_reductase_inhibitor</th>\n",
              "      <th>11-beta-hsd1_inhibitor</th>\n",
              "      <th>acat_inhibitor</th>\n",
              "      <th>acetylcholine_receptor_agonist</th>\n",
              "      <th>acetylcholine_receptor_antagonist</th>\n",
              "      <th>acetylcholinesterase_inhibitor</th>\n",
              "      <th>adenosine_receptor_agonist</th>\n",
              "      <th>adenosine_receptor_antagonist</th>\n",
              "      <th>adenylyl_cyclase_activator</th>\n",
              "      <th>adrenergic_receptor_agonist</th>\n",
              "      <th>adrenergic_receptor_antagonist</th>\n",
              "      <th>akt_inhibitor</th>\n",
              "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
              "      <th>alk_inhibitor</th>\n",
              "      <th>ampk_activator</th>\n",
              "      <th>analgesic</th>\n",
              "      <th>androgen_receptor_agonist</th>\n",
              "      <th>androgen_receptor_antagonist</th>\n",
              "      <th>anesthetic_-_local</th>\n",
              "      <th>angiogenesis_inhibitor</th>\n",
              "      <th>angiotensin_receptor_antagonist</th>\n",
              "      <th>anti-inflammatory</th>\n",
              "      <th>antiarrhythmic</th>\n",
              "      <th>antibiotic</th>\n",
              "      <th>anticonvulsant</th>\n",
              "      <th>antifungal</th>\n",
              "      <th>antihistamine</th>\n",
              "      <th>antimalarial</th>\n",
              "      <th>antioxidant</th>\n",
              "      <th>antiprotozoal</th>\n",
              "      <th>antiviral</th>\n",
              "      <th>apoptosis_stimulant</th>\n",
              "      <th>aromatase_inhibitor</th>\n",
              "      <th>atm_kinase_inhibitor</th>\n",
              "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
              "      <th>atp_synthase_inhibitor</th>\n",
              "      <th>atpase_inhibitor</th>\n",
              "      <th>atr_kinase_inhibitor</th>\n",
              "      <th>aurora_kinase_inhibitor</th>\n",
              "      <th>autotaxin_inhibitor</th>\n",
              "      <th>...</th>\n",
              "      <th>protein_synthesis_inhibitor</th>\n",
              "      <th>protein_tyrosine_kinase_inhibitor</th>\n",
              "      <th>radiopaque_medium</th>\n",
              "      <th>raf_inhibitor</th>\n",
              "      <th>ras_gtpase_inhibitor</th>\n",
              "      <th>retinoid_receptor_agonist</th>\n",
              "      <th>retinoid_receptor_antagonist</th>\n",
              "      <th>rho_associated_kinase_inhibitor</th>\n",
              "      <th>ribonucleoside_reductase_inhibitor</th>\n",
              "      <th>rna_polymerase_inhibitor</th>\n",
              "      <th>serotonin_receptor_agonist</th>\n",
              "      <th>serotonin_receptor_antagonist</th>\n",
              "      <th>serotonin_reuptake_inhibitor</th>\n",
              "      <th>sigma_receptor_agonist</th>\n",
              "      <th>sigma_receptor_antagonist</th>\n",
              "      <th>smoothened_receptor_antagonist</th>\n",
              "      <th>sodium_channel_inhibitor</th>\n",
              "      <th>sphingosine_receptor_agonist</th>\n",
              "      <th>src_inhibitor</th>\n",
              "      <th>steroid</th>\n",
              "      <th>syk_inhibitor</th>\n",
              "      <th>tachykinin_antagonist</th>\n",
              "      <th>tgf-beta_receptor_inhibitor</th>\n",
              "      <th>thrombin_inhibitor</th>\n",
              "      <th>thymidylate_synthase_inhibitor</th>\n",
              "      <th>tlr_agonist</th>\n",
              "      <th>tlr_antagonist</th>\n",
              "      <th>tnf_inhibitor</th>\n",
              "      <th>topoisomerase_inhibitor</th>\n",
              "      <th>transient_receptor_potential_channel_antagonist</th>\n",
              "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
              "      <th>trpv_agonist</th>\n",
              "      <th>trpv_antagonist</th>\n",
              "      <th>tubulin_inhibitor</th>\n",
              "      <th>tyrosine_kinase_inhibitor</th>\n",
              "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
              "      <th>vegfr_inhibitor</th>\n",
              "      <th>vitamin_b</th>\n",
              "      <th>vitamin_d_receptor_agonist</th>\n",
              "      <th>wnt_inhibitor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.00000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000714</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.001008</td>\n",
              "      <td>0.007979</td>\n",
              "      <td>0.012640</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.002268</td>\n",
              "      <td>0.004031</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.011338</td>\n",
              "      <td>0.015117</td>\n",
              "      <td>0.002771</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.001764</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>0.003737</td>\n",
              "      <td>0.003359</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.001806</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.000966</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.004073</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.004031</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004325</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.002352</td>\n",
              "      <td>0.009364</td>\n",
              "      <td>0.000504</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.00147</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.009910</td>\n",
              "      <td>0.016965</td>\n",
              "      <td>0.001848</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.011212</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.002981</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.002520</td>\n",
              "      <td>0.001260</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.001554</td>\n",
              "      <td>0.001260</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.001512</td>\n",
              "      <td>0.005333</td>\n",
              "      <td>0.000756</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>0.013270</td>\n",
              "      <td>0.003065</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.007139</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.001638</td>\n",
              "      <td>0.001260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.026709</td>\n",
              "      <td>0.027483</td>\n",
              "      <td>0.031731</td>\n",
              "      <td>0.088967</td>\n",
              "      <td>0.111716</td>\n",
              "      <td>0.055283</td>\n",
              "      <td>0.047566</td>\n",
              "      <td>0.063365</td>\n",
              "      <td>0.022443</td>\n",
              "      <td>0.105876</td>\n",
              "      <td>0.122022</td>\n",
              "      <td>0.052573</td>\n",
              "      <td>0.017143</td>\n",
              "      <td>0.041960</td>\n",
              "      <td>0.022443</td>\n",
              "      <td>0.022443</td>\n",
              "      <td>0.044851</td>\n",
              "      <td>0.061020</td>\n",
              "      <td>0.057864</td>\n",
              "      <td>0.038852</td>\n",
              "      <td>0.039387</td>\n",
              "      <td>0.055283</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>0.042456</td>\n",
              "      <td>0.022443</td>\n",
              "      <td>0.023359</td>\n",
              "      <td>0.022443</td>\n",
              "      <td>0.027483</td>\n",
              "      <td>0.055283</td>\n",
              "      <td>0.038852</td>\n",
              "      <td>0.031063</td>\n",
              "      <td>0.045315</td>\n",
              "      <td>0.044383</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>0.006480</td>\n",
              "      <td>0.022443</td>\n",
              "      <td>0.063693</td>\n",
              "      <td>0.028236</td>\n",
              "      <td>0.063365</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065625</td>\n",
              "      <td>0.028236</td>\n",
              "      <td>0.048437</td>\n",
              "      <td>0.096317</td>\n",
              "      <td>0.022443</td>\n",
              "      <td>0.052969</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>0.03831</td>\n",
              "      <td>0.039387</td>\n",
              "      <td>0.032384</td>\n",
              "      <td>0.099057</td>\n",
              "      <td>0.129142</td>\n",
              "      <td>0.042946</td>\n",
              "      <td>0.038852</td>\n",
              "      <td>0.038852</td>\n",
              "      <td>0.032384</td>\n",
              "      <td>0.105293</td>\n",
              "      <td>0.032384</td>\n",
              "      <td>0.054522</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>0.028236</td>\n",
              "      <td>0.050133</td>\n",
              "      <td>0.035472</td>\n",
              "      <td>0.028236</td>\n",
              "      <td>0.039387</td>\n",
              "      <td>0.035472</td>\n",
              "      <td>0.017143</td>\n",
              "      <td>0.038852</td>\n",
              "      <td>0.072834</td>\n",
              "      <td>0.027483</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>0.032384</td>\n",
              "      <td>0.044851</td>\n",
              "      <td>0.114429</td>\n",
              "      <td>0.055283</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>0.084190</td>\n",
              "      <td>0.033025</td>\n",
              "      <td>0.040436</td>\n",
              "      <td>0.035472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 206 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       5-alpha_reductase_inhibitor  ...  wnt_inhibitor\n",
              "count                 23814.000000  ...   23814.000000\n",
              "mean                      0.000714  ...       0.001260\n",
              "std                       0.026709  ...       0.035472\n",
              "min                       0.000000  ...       0.000000\n",
              "25%                       0.000000  ...       0.000000\n",
              "50%                       0.000000  ...       0.000000\n",
              "75%                       0.000000  ...       0.000000\n",
              "max                       1.000000  ...       1.000000\n",
              "\n",
              "[8 rows x 206 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W-GumnGMeZG"
      },
      "source": [
        "## Carregando os dados dos experimentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtuzmS_HMeZH"
      },
      "source": [
        "dados_experimentos = pd.read_csv('https://www.dropbox.com/s/5hix6c2oo43d4jj/dados_experimentos.csv?dl=1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MAJ-cChMeZH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "d643e7c1-90b5-4832-a39d-2911aabcd482"
      },
      "source": [
        "dados_experimentos.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tratamento</th>\n",
              "      <th>tempo</th>\n",
              "      <th>dose</th>\n",
              "      <th>droga</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>...</th>\n",
              "      <th>c-60</th>\n",
              "      <th>c-61</th>\n",
              "      <th>c-62</th>\n",
              "      <th>c-63</th>\n",
              "      <th>c-64</th>\n",
              "      <th>c-65</th>\n",
              "      <th>c-66</th>\n",
              "      <th>c-67</th>\n",
              "      <th>c-68</th>\n",
              "      <th>c-69</th>\n",
              "      <th>c-70</th>\n",
              "      <th>c-71</th>\n",
              "      <th>c-72</th>\n",
              "      <th>c-73</th>\n",
              "      <th>c-74</th>\n",
              "      <th>c-75</th>\n",
              "      <th>c-76</th>\n",
              "      <th>c-77</th>\n",
              "      <th>c-78</th>\n",
              "      <th>c-79</th>\n",
              "      <th>c-80</th>\n",
              "      <th>c-81</th>\n",
              "      <th>c-82</th>\n",
              "      <th>c-83</th>\n",
              "      <th>c-84</th>\n",
              "      <th>c-85</th>\n",
              "      <th>c-86</th>\n",
              "      <th>c-87</th>\n",
              "      <th>c-88</th>\n",
              "      <th>c-89</th>\n",
              "      <th>c-90</th>\n",
              "      <th>c-91</th>\n",
              "      <th>c-92</th>\n",
              "      <th>c-93</th>\n",
              "      <th>c-94</th>\n",
              "      <th>c-95</th>\n",
              "      <th>c-96</th>\n",
              "      <th>c-97</th>\n",
              "      <th>c-98</th>\n",
              "      <th>c-99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D1</td>\n",
              "      <td>b68db1d53</td>\n",
              "      <td>1.0620</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-0.6208</td>\n",
              "      <td>-0.1944</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>-1.0220</td>\n",
              "      <td>-0.0326</td>\n",
              "      <td>0.5548</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.5574</td>\n",
              "      <td>-0.4015</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>-0.6528</td>\n",
              "      <td>-0.7969</td>\n",
              "      <td>0.6342</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>-0.3694</td>\n",
              "      <td>-0.5688</td>\n",
              "      <td>-1.1360</td>\n",
              "      <td>-1.1880</td>\n",
              "      <td>0.6940</td>\n",
              "      <td>0.4393</td>\n",
              "      <td>0.2664</td>\n",
              "      <td>0.1907</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>-0.2853</td>\n",
              "      <td>0.5819</td>\n",
              "      <td>0.2934</td>\n",
              "      <td>-0.5584</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.3010</td>\n",
              "      <td>-0.1537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4805</td>\n",
              "      <td>0.4965</td>\n",
              "      <td>0.3680</td>\n",
              "      <td>0.8427</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>0.1403</td>\n",
              "      <td>0.1758</td>\n",
              "      <td>1.2570</td>\n",
              "      <td>-0.5979</td>\n",
              "      <td>1.2250</td>\n",
              "      <td>-0.0553</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0.5810</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.0495</td>\n",
              "      <td>0.4141</td>\n",
              "      <td>0.8432</td>\n",
              "      <td>0.6162</td>\n",
              "      <td>-0.7318</td>\n",
              "      <td>1.2120</td>\n",
              "      <td>0.6362</td>\n",
              "      <td>-0.4427</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>1.4840</td>\n",
              "      <td>0.1799</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>-0.1111</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>0.6685</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.8076</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.1912</td>\n",
              "      <td>0.6584</td>\n",
              "      <td>-0.3981</td>\n",
              "      <td>0.2139</td>\n",
              "      <td>0.3801</td>\n",
              "      <td>0.4176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D1</td>\n",
              "      <td>df89a8e5a</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.2991</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>1.0190</td>\n",
              "      <td>0.5207</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>-0.4047</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>-1.1520</td>\n",
              "      <td>-0.4201</td>\n",
              "      <td>-0.0958</td>\n",
              "      <td>0.4590</td>\n",
              "      <td>0.0803</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.5293</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>-0.3494</td>\n",
              "      <td>0.2883</td>\n",
              "      <td>0.9449</td>\n",
              "      <td>-0.1646</td>\n",
              "      <td>-0.2657</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.3135</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>-0.4216</td>\n",
              "      <td>-0.1161</td>\n",
              "      <td>-0.0499</td>\n",
              "      <td>-0.2627</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>-0.2483</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.4083</td>\n",
              "      <td>0.0319</td>\n",
              "      <td>0.3905</td>\n",
              "      <td>0.7099</td>\n",
              "      <td>0.2912</td>\n",
              "      <td>0.4151</td>\n",
              "      <td>-0.2840</td>\n",
              "      <td>-0.3104</td>\n",
              "      <td>-0.6373</td>\n",
              "      <td>0.2887</td>\n",
              "      <td>-0.0765</td>\n",
              "      <td>0.2539</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.5932</td>\n",
              "      <td>0.2031</td>\n",
              "      <td>0.7639</td>\n",
              "      <td>0.5499</td>\n",
              "      <td>-0.3322</td>\n",
              "      <td>-0.0977</td>\n",
              "      <td>0.4329</td>\n",
              "      <td>-0.2782</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.5934</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.9366</td>\n",
              "      <td>0.8193</td>\n",
              "      <td>-0.4236</td>\n",
              "      <td>0.3192</td>\n",
              "      <td>-0.4265</td>\n",
              "      <td>0.7543</td>\n",
              "      <td>0.4708</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>0.4899</td>\n",
              "      <td>0.1522</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.6077</td>\n",
              "      <td>0.7371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>18bb41b2c</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.5817</td>\n",
              "      <td>1.5540</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>1.2390</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.4797</td>\n",
              "      <td>-0.5631</td>\n",
              "      <td>-0.0366</td>\n",
              "      <td>-1.8300</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>-0.3278</td>\n",
              "      <td>0.6042</td>\n",
              "      <td>-0.3075</td>\n",
              "      <td>-0.1147</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0799</td>\n",
              "      <td>-0.8181</td>\n",
              "      <td>-1.5320</td>\n",
              "      <td>0.2307</td>\n",
              "      <td>0.4901</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>-1.3970</td>\n",
              "      <td>4.6240</td>\n",
              "      <td>-0.0437</td>\n",
              "      <td>1.2870</td>\n",
              "      <td>-1.8530</td>\n",
              "      <td>0.6069</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.1783</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5477</td>\n",
              "      <td>-0.7576</td>\n",
              "      <td>-0.0444</td>\n",
              "      <td>0.1894</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-2.3640</td>\n",
              "      <td>-0.4682</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>-0.5177</td>\n",
              "      <td>-0.0604</td>\n",
              "      <td>0.1682</td>\n",
              "      <td>-0.4436</td>\n",
              "      <td>0.4963</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.9760</td>\n",
              "      <td>-0.0427</td>\n",
              "      <td>-0.1235</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0690</td>\n",
              "      <td>-0.9416</td>\n",
              "      <td>-0.7548</td>\n",
              "      <td>-0.1109</td>\n",
              "      <td>-0.6272</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>0.1172</td>\n",
              "      <td>0.1093</td>\n",
              "      <td>-0.3113</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>-0.0873</td>\n",
              "      <td>-0.7250</td>\n",
              "      <td>-0.6297</td>\n",
              "      <td>0.6103</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>-1.3240</td>\n",
              "      <td>-0.3174</td>\n",
              "      <td>-0.6417</td>\n",
              "      <td>-0.2187</td>\n",
              "      <td>-1.4080</td>\n",
              "      <td>0.6931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>8c7f86626</td>\n",
              "      <td>-0.5138</td>\n",
              "      <td>-0.2491</td>\n",
              "      <td>-0.2656</td>\n",
              "      <td>0.5288</td>\n",
              "      <td>4.0620</td>\n",
              "      <td>-0.8095</td>\n",
              "      <td>-1.9590</td>\n",
              "      <td>0.1792</td>\n",
              "      <td>-0.1321</td>\n",
              "      <td>-1.0600</td>\n",
              "      <td>-0.8269</td>\n",
              "      <td>-0.3584</td>\n",
              "      <td>-0.8511</td>\n",
              "      <td>-0.5844</td>\n",
              "      <td>-2.5690</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>-0.8554</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>-2.3520</td>\n",
              "      <td>2.1200</td>\n",
              "      <td>-1.1580</td>\n",
              "      <td>-0.7191</td>\n",
              "      <td>-0.8004</td>\n",
              "      <td>-1.4670</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>-0.8995</td>\n",
              "      <td>0.2406</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-1.0890</td>\n",
              "      <td>-0.7575</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>-2.7370</td>\n",
              "      <td>0.8745</td>\n",
              "      <td>0.5787</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.1220</td>\n",
              "      <td>-0.3752</td>\n",
              "      <td>-2.3820</td>\n",
              "      <td>-3.7350</td>\n",
              "      <td>-2.9740</td>\n",
              "      <td>-1.4930</td>\n",
              "      <td>-1.6600</td>\n",
              "      <td>-3.1660</td>\n",
              "      <td>0.2816</td>\n",
              "      <td>-0.2990</td>\n",
              "      <td>-1.1870</td>\n",
              "      <td>-0.5044</td>\n",
              "      <td>-1.7750</td>\n",
              "      <td>-1.6120</td>\n",
              "      <td>-0.9215</td>\n",
              "      <td>-1.0810</td>\n",
              "      <td>-3.0520</td>\n",
              "      <td>-3.4470</td>\n",
              "      <td>-2.7740</td>\n",
              "      <td>-1.8460</td>\n",
              "      <td>-0.5568</td>\n",
              "      <td>-3.3960</td>\n",
              "      <td>-2.9510</td>\n",
              "      <td>-1.1550</td>\n",
              "      <td>-3.2620</td>\n",
              "      <td>-1.5390</td>\n",
              "      <td>-2.4600</td>\n",
              "      <td>-0.9417</td>\n",
              "      <td>-1.5550</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>-2.0990</td>\n",
              "      <td>-0.6441</td>\n",
              "      <td>-5.6300</td>\n",
              "      <td>-1.3780</td>\n",
              "      <td>-0.8632</td>\n",
              "      <td>-1.2880</td>\n",
              "      <td>-1.6210</td>\n",
              "      <td>-0.8784</td>\n",
              "      <td>-0.3876</td>\n",
              "      <td>-0.8154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D2</td>\n",
              "      <td>7cbed3131</td>\n",
              "      <td>-0.3254</td>\n",
              "      <td>-0.4009</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>1.4180</td>\n",
              "      <td>-0.8244</td>\n",
              "      <td>-0.2800</td>\n",
              "      <td>-0.1498</td>\n",
              "      <td>-0.8789</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>-0.5121</td>\n",
              "      <td>-0.9577</td>\n",
              "      <td>1.1750</td>\n",
              "      <td>0.2042</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1244</td>\n",
              "      <td>-1.7090</td>\n",
              "      <td>-0.3543</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.3330</td>\n",
              "      <td>-0.2685</td>\n",
              "      <td>0.7649</td>\n",
              "      <td>0.2057</td>\n",
              "      <td>1.3720</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.8056</td>\n",
              "      <td>-0.3754</td>\n",
              "      <td>-1.2090</td>\n",
              "      <td>0.2965</td>\n",
              "      <td>-0.0712</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.6674</td>\n",
              "      <td>-0.0783</td>\n",
              "      <td>1.1740</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.2274</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1535</td>\n",
              "      <td>-0.4640</td>\n",
              "      <td>-0.5943</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5159</td>\n",
              "      <td>0.6091</td>\n",
              "      <td>0.1813</td>\n",
              "      <td>-0.4249</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5648</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.6376</td>\n",
              "      <td>-0.3966</td>\n",
              "      <td>-1.4950</td>\n",
              "      <td>-0.9625</td>\n",
              "      <td>-0.0541</td>\n",
              "      <td>0.6273</td>\n",
              "      <td>0.4563</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>0.8134</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.6054</td>\n",
              "      <td>-0.1824</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.6670</td>\n",
              "      <td>1.0690</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.3031</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.2885</td>\n",
              "      <td>-0.3786</td>\n",
              "      <td>0.7125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 877 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id tratamento  tempo dose  ...    c-96    c-97    c-98    c-99\n",
              "0  id_000644bb2  com_droga     24   D1  ... -0.3981  0.2139  0.3801  0.4176\n",
              "1  id_000779bfc  com_droga     72   D1  ...  0.1522  0.1241  0.6077  0.7371\n",
              "2  id_000a6266a  com_droga     48   D1  ... -0.6417 -0.2187 -1.4080  0.6931\n",
              "3  id_0015fd391  com_droga     48   D1  ... -1.6210 -0.8784 -0.3876 -0.8154\n",
              "4  id_001626bd3  com_droga     72   D2  ...  0.1094  0.2885 -0.3786  0.7125\n",
              "\n",
              "[5 rows x 877 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMPEWxJ9MeZI"
      },
      "source": [
        "#### Entendendo um pouco sobre a distribuição dos nossos do experimento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgZefOn4MeZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "e26ee422-c50f-4120-97f6-3a578e28020d"
      },
      "source": [
        "dados_experimentos.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tempo</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>g-35</th>\n",
              "      <th>g-36</th>\n",
              "      <th>g-37</th>\n",
              "      <th>g-38</th>\n",
              "      <th>...</th>\n",
              "      <th>c-60</th>\n",
              "      <th>c-61</th>\n",
              "      <th>c-62</th>\n",
              "      <th>c-63</th>\n",
              "      <th>c-64</th>\n",
              "      <th>c-65</th>\n",
              "      <th>c-66</th>\n",
              "      <th>c-67</th>\n",
              "      <th>c-68</th>\n",
              "      <th>c-69</th>\n",
              "      <th>c-70</th>\n",
              "      <th>c-71</th>\n",
              "      <th>c-72</th>\n",
              "      <th>c-73</th>\n",
              "      <th>c-74</th>\n",
              "      <th>c-75</th>\n",
              "      <th>c-76</th>\n",
              "      <th>c-77</th>\n",
              "      <th>c-78</th>\n",
              "      <th>c-79</th>\n",
              "      <th>c-80</th>\n",
              "      <th>c-81</th>\n",
              "      <th>c-82</th>\n",
              "      <th>c-83</th>\n",
              "      <th>c-84</th>\n",
              "      <th>c-85</th>\n",
              "      <th>c-86</th>\n",
              "      <th>c-87</th>\n",
              "      <th>c-88</th>\n",
              "      <th>c-89</th>\n",
              "      <th>c-90</th>\n",
              "      <th>c-91</th>\n",
              "      <th>c-92</th>\n",
              "      <th>c-93</th>\n",
              "      <th>c-94</th>\n",
              "      <th>c-95</th>\n",
              "      <th>c-96</th>\n",
              "      <th>c-97</th>\n",
              "      <th>c-98</th>\n",
              "      <th>c-99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "      <td>23814.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>48.020156</td>\n",
              "      <td>0.248366</td>\n",
              "      <td>-0.095684</td>\n",
              "      <td>0.152253</td>\n",
              "      <td>0.081971</td>\n",
              "      <td>0.057347</td>\n",
              "      <td>-0.138836</td>\n",
              "      <td>0.035961</td>\n",
              "      <td>-0.202651</td>\n",
              "      <td>-0.190083</td>\n",
              "      <td>0.119905</td>\n",
              "      <td>-0.123321</td>\n",
              "      <td>0.182307</td>\n",
              "      <td>0.143203</td>\n",
              "      <td>0.209402</td>\n",
              "      <td>-0.173884</td>\n",
              "      <td>-0.024432</td>\n",
              "      <td>0.126823</td>\n",
              "      <td>-0.146663</td>\n",
              "      <td>0.087687</td>\n",
              "      <td>-0.082982</td>\n",
              "      <td>-0.111908</td>\n",
              "      <td>-0.087379</td>\n",
              "      <td>0.047548</td>\n",
              "      <td>-0.117474</td>\n",
              "      <td>-0.113212</td>\n",
              "      <td>-0.052746</td>\n",
              "      <td>-0.091055</td>\n",
              "      <td>0.112176</td>\n",
              "      <td>-0.046458</td>\n",
              "      <td>-0.076239</td>\n",
              "      <td>-0.197699</td>\n",
              "      <td>0.382177</td>\n",
              "      <td>-0.189432</td>\n",
              "      <td>0.078791</td>\n",
              "      <td>-0.093312</td>\n",
              "      <td>0.135729</td>\n",
              "      <td>-0.188616</td>\n",
              "      <td>-0.606710</td>\n",
              "      <td>0.534425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.517397</td>\n",
              "      <td>-0.360770</td>\n",
              "      <td>-0.435752</td>\n",
              "      <td>-0.613591</td>\n",
              "      <td>-0.402083</td>\n",
              "      <td>-0.619682</td>\n",
              "      <td>-0.452265</td>\n",
              "      <td>-0.497164</td>\n",
              "      <td>-0.413836</td>\n",
              "      <td>-0.277029</td>\n",
              "      <td>-0.547845</td>\n",
              "      <td>-0.358611</td>\n",
              "      <td>-0.442906</td>\n",
              "      <td>-0.475194</td>\n",
              "      <td>-0.010404</td>\n",
              "      <td>-0.467001</td>\n",
              "      <td>-0.276963</td>\n",
              "      <td>-0.455848</td>\n",
              "      <td>-0.412918</td>\n",
              "      <td>-0.456404</td>\n",
              "      <td>-0.472514</td>\n",
              "      <td>-0.505481</td>\n",
              "      <td>-0.492735</td>\n",
              "      <td>-0.446836</td>\n",
              "      <td>-0.463029</td>\n",
              "      <td>-0.409310</td>\n",
              "      <td>-0.333124</td>\n",
              "      <td>-0.295009</td>\n",
              "      <td>-0.328342</td>\n",
              "      <td>-0.401615</td>\n",
              "      <td>-0.469244</td>\n",
              "      <td>-0.461411</td>\n",
              "      <td>-0.513256</td>\n",
              "      <td>-0.500142</td>\n",
              "      <td>-0.507093</td>\n",
              "      <td>-0.353726</td>\n",
              "      <td>-0.463485</td>\n",
              "      <td>-0.378241</td>\n",
              "      <td>-0.470252</td>\n",
              "      <td>-0.301505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>19.402807</td>\n",
              "      <td>1.393399</td>\n",
              "      <td>0.812363</td>\n",
              "      <td>1.035731</td>\n",
              "      <td>0.950012</td>\n",
              "      <td>1.032091</td>\n",
              "      <td>1.179388</td>\n",
              "      <td>0.882395</td>\n",
              "      <td>1.125494</td>\n",
              "      <td>1.749885</td>\n",
              "      <td>1.087180</td>\n",
              "      <td>1.291501</td>\n",
              "      <td>1.253604</td>\n",
              "      <td>1.234590</td>\n",
              "      <td>1.273068</td>\n",
              "      <td>1.247178</td>\n",
              "      <td>0.659839</td>\n",
              "      <td>1.418997</td>\n",
              "      <td>1.179688</td>\n",
              "      <td>0.743301</td>\n",
              "      <td>0.844796</td>\n",
              "      <td>1.219529</td>\n",
              "      <td>0.824401</td>\n",
              "      <td>0.924838</td>\n",
              "      <td>0.760159</td>\n",
              "      <td>1.203186</td>\n",
              "      <td>0.866977</td>\n",
              "      <td>1.103765</td>\n",
              "      <td>1.001687</td>\n",
              "      <td>1.027758</td>\n",
              "      <td>1.279399</td>\n",
              "      <td>1.302567</td>\n",
              "      <td>1.559174</td>\n",
              "      <td>0.933514</td>\n",
              "      <td>1.172270</td>\n",
              "      <td>1.174325</td>\n",
              "      <td>1.061719</td>\n",
              "      <td>1.397677</td>\n",
              "      <td>2.200277</td>\n",
              "      <td>2.003317</td>\n",
              "      <td>...</td>\n",
              "      <td>2.122318</td>\n",
              "      <td>1.710725</td>\n",
              "      <td>1.898871</td>\n",
              "      <td>2.307820</td>\n",
              "      <td>1.785055</td>\n",
              "      <td>2.225596</td>\n",
              "      <td>1.991021</td>\n",
              "      <td>2.063896</td>\n",
              "      <td>1.887001</td>\n",
              "      <td>1.459639</td>\n",
              "      <td>2.187835</td>\n",
              "      <td>1.730634</td>\n",
              "      <td>1.924716</td>\n",
              "      <td>2.021927</td>\n",
              "      <td>1.029820</td>\n",
              "      <td>2.004317</td>\n",
              "      <td>1.429340</td>\n",
              "      <td>1.924263</td>\n",
              "      <td>1.888788</td>\n",
              "      <td>1.832863</td>\n",
              "      <td>2.011396</td>\n",
              "      <td>2.091353</td>\n",
              "      <td>2.055624</td>\n",
              "      <td>1.987476</td>\n",
              "      <td>2.014045</td>\n",
              "      <td>1.883974</td>\n",
              "      <td>1.647241</td>\n",
              "      <td>1.634073</td>\n",
              "      <td>1.663170</td>\n",
              "      <td>1.832794</td>\n",
              "      <td>2.000488</td>\n",
              "      <td>2.042475</td>\n",
              "      <td>2.001714</td>\n",
              "      <td>2.107105</td>\n",
              "      <td>2.159589</td>\n",
              "      <td>1.629291</td>\n",
              "      <td>2.059725</td>\n",
              "      <td>1.703615</td>\n",
              "      <td>1.834828</td>\n",
              "      <td>1.407918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>24.000000</td>\n",
              "      <td>-5.513000</td>\n",
              "      <td>-5.737000</td>\n",
              "      <td>-9.104000</td>\n",
              "      <td>-5.998000</td>\n",
              "      <td>-6.369000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-8.337000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-5.870000</td>\n",
              "      <td>-8.587000</td>\n",
              "      <td>-5.018000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-4.226000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-5.700000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-8.272000</td>\n",
              "      <td>-8.184000</td>\n",
              "      <td>-4.835000</td>\n",
              "      <td>-7.913000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-2.956000</td>\n",
              "      <td>-8.356000</td>\n",
              "      <td>-7.182000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-9.261000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-9.839000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-6.452000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-9.938000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "      <td>-10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>24.000000</td>\n",
              "      <td>-0.473075</td>\n",
              "      <td>-0.562200</td>\n",
              "      <td>-0.437750</td>\n",
              "      <td>-0.429575</td>\n",
              "      <td>-0.470925</td>\n",
              "      <td>-0.602225</td>\n",
              "      <td>-0.493900</td>\n",
              "      <td>-0.525175</td>\n",
              "      <td>-0.511675</td>\n",
              "      <td>-0.360200</td>\n",
              "      <td>-0.511475</td>\n",
              "      <td>-0.489675</td>\n",
              "      <td>-0.447500</td>\n",
              "      <td>-0.481200</td>\n",
              "      <td>-0.607975</td>\n",
              "      <td>-0.404150</td>\n",
              "      <td>-0.391950</td>\n",
              "      <td>-0.513775</td>\n",
              "      <td>-0.272200</td>\n",
              "      <td>-0.488675</td>\n",
              "      <td>-0.524600</td>\n",
              "      <td>-0.538900</td>\n",
              "      <td>-0.440375</td>\n",
              "      <td>-0.508900</td>\n",
              "      <td>-0.533900</td>\n",
              "      <td>-0.497700</td>\n",
              "      <td>-0.512875</td>\n",
              "      <td>-0.467800</td>\n",
              "      <td>-0.378300</td>\n",
              "      <td>-0.505750</td>\n",
              "      <td>-0.457975</td>\n",
              "      <td>-0.328200</td>\n",
              "      <td>-0.600500</td>\n",
              "      <td>-0.478700</td>\n",
              "      <td>-0.570525</td>\n",
              "      <td>-0.481800</td>\n",
              "      <td>-0.541950</td>\n",
              "      <td>-0.604100</td>\n",
              "      <td>-0.470250</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.588075</td>\n",
              "      <td>-0.564025</td>\n",
              "      <td>-0.561000</td>\n",
              "      <td>-0.583250</td>\n",
              "      <td>-0.566500</td>\n",
              "      <td>-0.603200</td>\n",
              "      <td>-0.541575</td>\n",
              "      <td>-0.560825</td>\n",
              "      <td>-0.555200</td>\n",
              "      <td>-0.534500</td>\n",
              "      <td>-0.569100</td>\n",
              "      <td>-0.558300</td>\n",
              "      <td>-0.573350</td>\n",
              "      <td>-0.594275</td>\n",
              "      <td>-0.389925</td>\n",
              "      <td>-0.551200</td>\n",
              "      <td>-0.544150</td>\n",
              "      <td>-0.575075</td>\n",
              "      <td>-0.568275</td>\n",
              "      <td>-0.582650</td>\n",
              "      <td>-0.558575</td>\n",
              "      <td>-0.562375</td>\n",
              "      <td>-0.572800</td>\n",
              "      <td>-0.561225</td>\n",
              "      <td>-0.560675</td>\n",
              "      <td>-0.560100</td>\n",
              "      <td>-0.533700</td>\n",
              "      <td>-0.504575</td>\n",
              "      <td>-0.544275</td>\n",
              "      <td>-0.569150</td>\n",
              "      <td>-0.566175</td>\n",
              "      <td>-0.565975</td>\n",
              "      <td>-0.589975</td>\n",
              "      <td>-0.568700</td>\n",
              "      <td>-0.563775</td>\n",
              "      <td>-0.567975</td>\n",
              "      <td>-0.552575</td>\n",
              "      <td>-0.561000</td>\n",
              "      <td>-0.592600</td>\n",
              "      <td>-0.562900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>-0.008850</td>\n",
              "      <td>-0.046600</td>\n",
              "      <td>0.075200</td>\n",
              "      <td>0.008050</td>\n",
              "      <td>-0.026900</td>\n",
              "      <td>-0.015650</td>\n",
              "      <td>-0.000650</td>\n",
              "      <td>-0.017900</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.160450</td>\n",
              "      <td>0.038550</td>\n",
              "      <td>0.013800</td>\n",
              "      <td>0.060250</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>-0.030100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149400</td>\n",
              "      <td>-0.002200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.027800</td>\n",
              "      <td>-0.002800</td>\n",
              "      <td>-0.069350</td>\n",
              "      <td>-0.011800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018300</td>\n",
              "      <td>-0.011650</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.037600</td>\n",
              "      <td>0.003750</td>\n",
              "      <td>0.021750</td>\n",
              "      <td>0.027000</td>\n",
              "      <td>0.019100</td>\n",
              "      <td>-0.054000</td>\n",
              "      <td>0.023350</td>\n",
              "      <td>0.003350</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>0.015350</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017650</td>\n",
              "      <td>-0.041550</td>\n",
              "      <td>-0.002950</td>\n",
              "      <td>-0.012650</td>\n",
              "      <td>-0.005600</td>\n",
              "      <td>0.007650</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.023800</td>\n",
              "      <td>-0.011450</td>\n",
              "      <td>-0.007100</td>\n",
              "      <td>-0.019500</td>\n",
              "      <td>-0.019500</td>\n",
              "      <td>-0.009300</td>\n",
              "      <td>0.081550</td>\n",
              "      <td>-0.006900</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>-0.014650</td>\n",
              "      <td>-0.014350</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>-0.005300</td>\n",
              "      <td>-0.004050</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>-0.007900</td>\n",
              "      <td>-0.004600</td>\n",
              "      <td>-0.002400</td>\n",
              "      <td>0.007850</td>\n",
              "      <td>-0.005600</td>\n",
              "      <td>-0.020600</td>\n",
              "      <td>-0.030000</td>\n",
              "      <td>-0.009900</td>\n",
              "      <td>0.003250</td>\n",
              "      <td>-0.009100</td>\n",
              "      <td>-0.013750</td>\n",
              "      <td>-0.003300</td>\n",
              "      <td>-0.010250</td>\n",
              "      <td>-0.001250</td>\n",
              "      <td>-0.006800</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>-0.019500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.525700</td>\n",
              "      <td>0.403075</td>\n",
              "      <td>0.663925</td>\n",
              "      <td>0.463400</td>\n",
              "      <td>0.465375</td>\n",
              "      <td>0.510425</td>\n",
              "      <td>0.528725</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.549225</td>\n",
              "      <td>0.697775</td>\n",
              "      <td>0.525400</td>\n",
              "      <td>0.575275</td>\n",
              "      <td>0.604450</td>\n",
              "      <td>0.575825</td>\n",
              "      <td>0.457975</td>\n",
              "      <td>0.382475</td>\n",
              "      <td>0.829500</td>\n",
              "      <td>0.494775</td>\n",
              "      <td>0.327800</td>\n",
              "      <td>0.400600</td>\n",
              "      <td>0.492400</td>\n",
              "      <td>0.414875</td>\n",
              "      <td>0.433400</td>\n",
              "      <td>0.329250</td>\n",
              "      <td>0.527700</td>\n",
              "      <td>0.461650</td>\n",
              "      <td>0.508425</td>\n",
              "      <td>0.586450</td>\n",
              "      <td>0.431275</td>\n",
              "      <td>0.507600</td>\n",
              "      <td>0.458075</td>\n",
              "      <td>0.471075</td>\n",
              "      <td>0.391950</td>\n",
              "      <td>0.551300</td>\n",
              "      <td>0.503725</td>\n",
              "      <td>0.564875</td>\n",
              "      <td>0.517025</td>\n",
              "      <td>0.460500</td>\n",
              "      <td>0.642300</td>\n",
              "      <td>...</td>\n",
              "      <td>0.452675</td>\n",
              "      <td>0.427675</td>\n",
              "      <td>0.462175</td>\n",
              "      <td>0.447975</td>\n",
              "      <td>0.447150</td>\n",
              "      <td>0.441250</td>\n",
              "      <td>0.470600</td>\n",
              "      <td>0.458550</td>\n",
              "      <td>0.441000</td>\n",
              "      <td>0.460075</td>\n",
              "      <td>0.460950</td>\n",
              "      <td>0.449975</td>\n",
              "      <td>0.445200</td>\n",
              "      <td>0.473200</td>\n",
              "      <td>0.563575</td>\n",
              "      <td>0.456350</td>\n",
              "      <td>0.493400</td>\n",
              "      <td>0.448375</td>\n",
              "      <td>0.451975</td>\n",
              "      <td>0.463075</td>\n",
              "      <td>0.447675</td>\n",
              "      <td>0.462000</td>\n",
              "      <td>0.468900</td>\n",
              "      <td>0.452375</td>\n",
              "      <td>0.460475</td>\n",
              "      <td>0.461675</td>\n",
              "      <td>0.465950</td>\n",
              "      <td>0.463400</td>\n",
              "      <td>0.450075</td>\n",
              "      <td>0.430875</td>\n",
              "      <td>0.457750</td>\n",
              "      <td>0.461500</td>\n",
              "      <td>0.445675</td>\n",
              "      <td>0.452900</td>\n",
              "      <td>0.470900</td>\n",
              "      <td>0.444750</td>\n",
              "      <td>0.465225</td>\n",
              "      <td>0.446400</td>\n",
              "      <td>0.461275</td>\n",
              "      <td>0.438650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>72.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.039000</td>\n",
              "      <td>8.257000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>7.282000</td>\n",
              "      <td>7.333000</td>\n",
              "      <td>5.473000</td>\n",
              "      <td>8.887000</td>\n",
              "      <td>6.433000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.134000</td>\n",
              "      <td>6.418000</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>8.872000</td>\n",
              "      <td>4.081000</td>\n",
              "      <td>9.842000</td>\n",
              "      <td>5.248000</td>\n",
              "      <td>5.942000</td>\n",
              "      <td>5.201000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8.494000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.416000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6.796000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>5.834000</td>\n",
              "      <td>5.602000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.888000</td>\n",
              "      <td>3.596000</td>\n",
              "      <td>4.857000</td>\n",
              "      <td>3.549000</td>\n",
              "      <td>3.382000</td>\n",
              "      <td>3.328000</td>\n",
              "      <td>4.157000</td>\n",
              "      <td>3.736000</td>\n",
              "      <td>3.582000</td>\n",
              "      <td>3.119000</td>\n",
              "      <td>3.323000</td>\n",
              "      <td>5.014000</td>\n",
              "      <td>2.898000</td>\n",
              "      <td>4.185000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>3.276000</td>\n",
              "      <td>4.992000</td>\n",
              "      <td>3.770000</td>\n",
              "      <td>2.851000</td>\n",
              "      <td>3.211000</td>\n",
              "      <td>4.534000</td>\n",
              "      <td>3.890000</td>\n",
              "      <td>3.994000</td>\n",
              "      <td>4.321000</td>\n",
              "      <td>4.020000</td>\n",
              "      <td>3.738000</td>\n",
              "      <td>3.252000</td>\n",
              "      <td>5.406000</td>\n",
              "      <td>3.110000</td>\n",
              "      <td>3.320000</td>\n",
              "      <td>4.069000</td>\n",
              "      <td>3.960000</td>\n",
              "      <td>3.927000</td>\n",
              "      <td>3.596000</td>\n",
              "      <td>3.747000</td>\n",
              "      <td>2.814000</td>\n",
              "      <td>3.505000</td>\n",
              "      <td>2.924000</td>\n",
              "      <td>3.111000</td>\n",
              "      <td>3.805000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 873 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              tempo           g-0  ...          c-98          c-99\n",
              "count  23814.000000  23814.000000  ...  23814.000000  23814.000000\n",
              "mean      48.020156      0.248366  ...     -0.470252     -0.301505\n",
              "std       19.402807      1.393399  ...      1.834828      1.407918\n",
              "min       24.000000     -5.513000  ...    -10.000000    -10.000000\n",
              "25%       24.000000     -0.473075  ...     -0.592600     -0.562900\n",
              "50%       48.000000     -0.008850  ...      0.014000     -0.019500\n",
              "75%       72.000000      0.525700  ...      0.461275      0.438650\n",
              "max       72.000000     10.000000  ...      3.111000      3.805000\n",
              "\n",
              "[8 rows x 873 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGlZFPLCMeZJ"
      },
      "source": [
        "### Feature engineer para criar coluna de informação sobre ativação e número de ativações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgBuFtP3MeZJ"
      },
      "source": [
        "dados_resultados['n_moa'] = dados_resultados.drop('id', axis=1).sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiY1KJ2UMeZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "529a1792-ab15-405d-d723-14a7ebf74f6a"
      },
      "source": [
        "dados_resultados['ativo_moa'] = (dados_resultados['n_moa'] != 0)\n",
        "dados_resultados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>5-alpha_reductase_inhibitor</th>\n",
              "      <th>11-beta-hsd1_inhibitor</th>\n",
              "      <th>acat_inhibitor</th>\n",
              "      <th>acetylcholine_receptor_agonist</th>\n",
              "      <th>acetylcholine_receptor_antagonist</th>\n",
              "      <th>acetylcholinesterase_inhibitor</th>\n",
              "      <th>adenosine_receptor_agonist</th>\n",
              "      <th>adenosine_receptor_antagonist</th>\n",
              "      <th>adenylyl_cyclase_activator</th>\n",
              "      <th>adrenergic_receptor_agonist</th>\n",
              "      <th>adrenergic_receptor_antagonist</th>\n",
              "      <th>akt_inhibitor</th>\n",
              "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
              "      <th>alk_inhibitor</th>\n",
              "      <th>ampk_activator</th>\n",
              "      <th>analgesic</th>\n",
              "      <th>androgen_receptor_agonist</th>\n",
              "      <th>androgen_receptor_antagonist</th>\n",
              "      <th>anesthetic_-_local</th>\n",
              "      <th>angiogenesis_inhibitor</th>\n",
              "      <th>angiotensin_receptor_antagonist</th>\n",
              "      <th>anti-inflammatory</th>\n",
              "      <th>antiarrhythmic</th>\n",
              "      <th>antibiotic</th>\n",
              "      <th>anticonvulsant</th>\n",
              "      <th>antifungal</th>\n",
              "      <th>antihistamine</th>\n",
              "      <th>antimalarial</th>\n",
              "      <th>antioxidant</th>\n",
              "      <th>antiprotozoal</th>\n",
              "      <th>antiviral</th>\n",
              "      <th>apoptosis_stimulant</th>\n",
              "      <th>aromatase_inhibitor</th>\n",
              "      <th>atm_kinase_inhibitor</th>\n",
              "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
              "      <th>atp_synthase_inhibitor</th>\n",
              "      <th>atpase_inhibitor</th>\n",
              "      <th>atr_kinase_inhibitor</th>\n",
              "      <th>aurora_kinase_inhibitor</th>\n",
              "      <th>...</th>\n",
              "      <th>radiopaque_medium</th>\n",
              "      <th>raf_inhibitor</th>\n",
              "      <th>ras_gtpase_inhibitor</th>\n",
              "      <th>retinoid_receptor_agonist</th>\n",
              "      <th>retinoid_receptor_antagonist</th>\n",
              "      <th>rho_associated_kinase_inhibitor</th>\n",
              "      <th>ribonucleoside_reductase_inhibitor</th>\n",
              "      <th>rna_polymerase_inhibitor</th>\n",
              "      <th>serotonin_receptor_agonist</th>\n",
              "      <th>serotonin_receptor_antagonist</th>\n",
              "      <th>serotonin_reuptake_inhibitor</th>\n",
              "      <th>sigma_receptor_agonist</th>\n",
              "      <th>sigma_receptor_antagonist</th>\n",
              "      <th>smoothened_receptor_antagonist</th>\n",
              "      <th>sodium_channel_inhibitor</th>\n",
              "      <th>sphingosine_receptor_agonist</th>\n",
              "      <th>src_inhibitor</th>\n",
              "      <th>steroid</th>\n",
              "      <th>syk_inhibitor</th>\n",
              "      <th>tachykinin_antagonist</th>\n",
              "      <th>tgf-beta_receptor_inhibitor</th>\n",
              "      <th>thrombin_inhibitor</th>\n",
              "      <th>thymidylate_synthase_inhibitor</th>\n",
              "      <th>tlr_agonist</th>\n",
              "      <th>tlr_antagonist</th>\n",
              "      <th>tnf_inhibitor</th>\n",
              "      <th>topoisomerase_inhibitor</th>\n",
              "      <th>transient_receptor_potential_channel_antagonist</th>\n",
              "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
              "      <th>trpv_agonist</th>\n",
              "      <th>trpv_antagonist</th>\n",
              "      <th>tubulin_inhibitor</th>\n",
              "      <th>tyrosine_kinase_inhibitor</th>\n",
              "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
              "      <th>vegfr_inhibitor</th>\n",
              "      <th>vitamin_b</th>\n",
              "      <th>vitamin_d_receptor_agonist</th>\n",
              "      <th>wnt_inhibitor</th>\n",
              "      <th>n_moa</th>\n",
              "      <th>ativo_moa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 209 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  5-alpha_reductase_inhibitor  ...  n_moa  ativo_moa\n",
              "0  id_000644bb2                            0  ...      1       True\n",
              "1  id_000779bfc                            0  ...      0      False\n",
              "2  id_000a6266a                            0  ...      3       True\n",
              "3  id_0015fd391                            0  ...      0      False\n",
              "4  id_001626bd3                            0  ...      1       True\n",
              "\n",
              "[5 rows x 209 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exVw6wnWMeZK"
      },
      "source": [
        "### Vamos agora unir os dados n_moa e ativo_moa na tabela de experimentos para olharmos a correlação das informações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZYnOiJ-MeZL"
      },
      "source": [
        "dados_combinados = pd.merge(dados_experimentos, dados_resultados[['id','n_moa', 'ativo_moa']], on='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2lKXYoCMeZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "9e70eca0-f676-4258-8e58-a6fb694a1504"
      },
      "source": [
        "dados_combinados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tratamento</th>\n",
              "      <th>tempo</th>\n",
              "      <th>dose</th>\n",
              "      <th>droga</th>\n",
              "      <th>g-0</th>\n",
              "      <th>g-1</th>\n",
              "      <th>g-2</th>\n",
              "      <th>g-3</th>\n",
              "      <th>g-4</th>\n",
              "      <th>g-5</th>\n",
              "      <th>g-6</th>\n",
              "      <th>g-7</th>\n",
              "      <th>g-8</th>\n",
              "      <th>g-9</th>\n",
              "      <th>g-10</th>\n",
              "      <th>g-11</th>\n",
              "      <th>g-12</th>\n",
              "      <th>g-13</th>\n",
              "      <th>g-14</th>\n",
              "      <th>g-15</th>\n",
              "      <th>g-16</th>\n",
              "      <th>g-17</th>\n",
              "      <th>g-18</th>\n",
              "      <th>g-19</th>\n",
              "      <th>g-20</th>\n",
              "      <th>g-21</th>\n",
              "      <th>g-22</th>\n",
              "      <th>g-23</th>\n",
              "      <th>g-24</th>\n",
              "      <th>g-25</th>\n",
              "      <th>g-26</th>\n",
              "      <th>g-27</th>\n",
              "      <th>g-28</th>\n",
              "      <th>g-29</th>\n",
              "      <th>g-30</th>\n",
              "      <th>g-31</th>\n",
              "      <th>g-32</th>\n",
              "      <th>g-33</th>\n",
              "      <th>g-34</th>\n",
              "      <th>...</th>\n",
              "      <th>c-62</th>\n",
              "      <th>c-63</th>\n",
              "      <th>c-64</th>\n",
              "      <th>c-65</th>\n",
              "      <th>c-66</th>\n",
              "      <th>c-67</th>\n",
              "      <th>c-68</th>\n",
              "      <th>c-69</th>\n",
              "      <th>c-70</th>\n",
              "      <th>c-71</th>\n",
              "      <th>c-72</th>\n",
              "      <th>c-73</th>\n",
              "      <th>c-74</th>\n",
              "      <th>c-75</th>\n",
              "      <th>c-76</th>\n",
              "      <th>c-77</th>\n",
              "      <th>c-78</th>\n",
              "      <th>c-79</th>\n",
              "      <th>c-80</th>\n",
              "      <th>c-81</th>\n",
              "      <th>c-82</th>\n",
              "      <th>c-83</th>\n",
              "      <th>c-84</th>\n",
              "      <th>c-85</th>\n",
              "      <th>c-86</th>\n",
              "      <th>c-87</th>\n",
              "      <th>c-88</th>\n",
              "      <th>c-89</th>\n",
              "      <th>c-90</th>\n",
              "      <th>c-91</th>\n",
              "      <th>c-92</th>\n",
              "      <th>c-93</th>\n",
              "      <th>c-94</th>\n",
              "      <th>c-95</th>\n",
              "      <th>c-96</th>\n",
              "      <th>c-97</th>\n",
              "      <th>c-98</th>\n",
              "      <th>c-99</th>\n",
              "      <th>n_moa</th>\n",
              "      <th>ativo_moa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_000644bb2</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>24</td>\n",
              "      <td>D1</td>\n",
              "      <td>b68db1d53</td>\n",
              "      <td>1.0620</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-0.6208</td>\n",
              "      <td>-0.1944</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>-1.0220</td>\n",
              "      <td>-0.0326</td>\n",
              "      <td>0.5548</td>\n",
              "      <td>-0.0921</td>\n",
              "      <td>1.1830</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.5574</td>\n",
              "      <td>-0.4015</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>-0.6528</td>\n",
              "      <td>-0.7969</td>\n",
              "      <td>0.6342</td>\n",
              "      <td>0.1778</td>\n",
              "      <td>-0.3694</td>\n",
              "      <td>-0.5688</td>\n",
              "      <td>-1.1360</td>\n",
              "      <td>-1.1880</td>\n",
              "      <td>0.6940</td>\n",
              "      <td>0.4393</td>\n",
              "      <td>0.2664</td>\n",
              "      <td>0.1907</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>-0.2853</td>\n",
              "      <td>0.5819</td>\n",
              "      <td>0.2934</td>\n",
              "      <td>-0.5584</td>\n",
              "      <td>-0.0916</td>\n",
              "      <td>-0.3010</td>\n",
              "      <td>-0.1537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3680</td>\n",
              "      <td>0.8427</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>0.1403</td>\n",
              "      <td>0.1758</td>\n",
              "      <td>1.2570</td>\n",
              "      <td>-0.5979</td>\n",
              "      <td>1.2250</td>\n",
              "      <td>-0.0553</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0.5810</td>\n",
              "      <td>0.9590</td>\n",
              "      <td>0.2427</td>\n",
              "      <td>0.0495</td>\n",
              "      <td>0.4141</td>\n",
              "      <td>0.8432</td>\n",
              "      <td>0.6162</td>\n",
              "      <td>-0.7318</td>\n",
              "      <td>1.2120</td>\n",
              "      <td>0.6362</td>\n",
              "      <td>-0.4427</td>\n",
              "      <td>0.1288</td>\n",
              "      <td>1.4840</td>\n",
              "      <td>0.1799</td>\n",
              "      <td>0.5367</td>\n",
              "      <td>-0.1111</td>\n",
              "      <td>-1.0120</td>\n",
              "      <td>0.6685</td>\n",
              "      <td>0.2862</td>\n",
              "      <td>0.2584</td>\n",
              "      <td>0.8076</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.1912</td>\n",
              "      <td>0.6584</td>\n",
              "      <td>-0.3981</td>\n",
              "      <td>0.2139</td>\n",
              "      <td>0.3801</td>\n",
              "      <td>0.4176</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_000779bfc</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D1</td>\n",
              "      <td>df89a8e5a</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.2991</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>1.0190</td>\n",
              "      <td>0.5207</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.3372</td>\n",
              "      <td>-0.4047</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>-1.1520</td>\n",
              "      <td>-0.4201</td>\n",
              "      <td>-0.0958</td>\n",
              "      <td>0.4590</td>\n",
              "      <td>0.0803</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.5293</td>\n",
              "      <td>0.2839</td>\n",
              "      <td>-0.3494</td>\n",
              "      <td>0.2883</td>\n",
              "      <td>0.9449</td>\n",
              "      <td>-0.1646</td>\n",
              "      <td>-0.2657</td>\n",
              "      <td>-0.3372</td>\n",
              "      <td>0.3135</td>\n",
              "      <td>-0.4316</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>0.2075</td>\n",
              "      <td>-0.4216</td>\n",
              "      <td>-0.1161</td>\n",
              "      <td>-0.0499</td>\n",
              "      <td>-0.2627</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>-0.2483</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.3905</td>\n",
              "      <td>0.7099</td>\n",
              "      <td>0.2912</td>\n",
              "      <td>0.4151</td>\n",
              "      <td>-0.2840</td>\n",
              "      <td>-0.3104</td>\n",
              "      <td>-0.6373</td>\n",
              "      <td>0.2887</td>\n",
              "      <td>-0.0765</td>\n",
              "      <td>0.2539</td>\n",
              "      <td>0.4443</td>\n",
              "      <td>0.5932</td>\n",
              "      <td>0.2031</td>\n",
              "      <td>0.7639</td>\n",
              "      <td>0.5499</td>\n",
              "      <td>-0.3322</td>\n",
              "      <td>-0.0977</td>\n",
              "      <td>0.4329</td>\n",
              "      <td>-0.2782</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.5934</td>\n",
              "      <td>0.3402</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.4420</td>\n",
              "      <td>0.9366</td>\n",
              "      <td>0.8193</td>\n",
              "      <td>-0.4236</td>\n",
              "      <td>0.3192</td>\n",
              "      <td>-0.4265</td>\n",
              "      <td>0.7543</td>\n",
              "      <td>0.4708</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>0.4899</td>\n",
              "      <td>0.1522</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.6077</td>\n",
              "      <td>0.7371</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_000a6266a</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>18bb41b2c</td>\n",
              "      <td>0.6280</td>\n",
              "      <td>0.5817</td>\n",
              "      <td>1.5540</td>\n",
              "      <td>-0.0764</td>\n",
              "      <td>-0.0323</td>\n",
              "      <td>1.2390</td>\n",
              "      <td>0.1715</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>-0.4797</td>\n",
              "      <td>-0.5631</td>\n",
              "      <td>-0.0366</td>\n",
              "      <td>-1.8300</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>-0.3278</td>\n",
              "      <td>0.6042</td>\n",
              "      <td>-0.3075</td>\n",
              "      <td>-0.1147</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.0799</td>\n",
              "      <td>-0.8181</td>\n",
              "      <td>-1.5320</td>\n",
              "      <td>0.2307</td>\n",
              "      <td>0.4901</td>\n",
              "      <td>0.4780</td>\n",
              "      <td>-1.3970</td>\n",
              "      <td>4.6240</td>\n",
              "      <td>-0.0437</td>\n",
              "      <td>1.2870</td>\n",
              "      <td>-1.8530</td>\n",
              "      <td>0.6069</td>\n",
              "      <td>0.4290</td>\n",
              "      <td>0.1783</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0444</td>\n",
              "      <td>0.1894</td>\n",
              "      <td>-0.0014</td>\n",
              "      <td>-2.3640</td>\n",
              "      <td>-0.4682</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>-0.5177</td>\n",
              "      <td>-0.0604</td>\n",
              "      <td>0.1682</td>\n",
              "      <td>-0.4436</td>\n",
              "      <td>0.4963</td>\n",
              "      <td>0.1363</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.9760</td>\n",
              "      <td>-0.0427</td>\n",
              "      <td>-0.1235</td>\n",
              "      <td>0.0959</td>\n",
              "      <td>0.0690</td>\n",
              "      <td>-0.9416</td>\n",
              "      <td>-0.7548</td>\n",
              "      <td>-0.1109</td>\n",
              "      <td>-0.6272</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>0.1172</td>\n",
              "      <td>0.1093</td>\n",
              "      <td>-0.3113</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>-0.0873</td>\n",
              "      <td>-0.7250</td>\n",
              "      <td>-0.6297</td>\n",
              "      <td>0.6103</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>-1.3240</td>\n",
              "      <td>-0.3174</td>\n",
              "      <td>-0.6417</td>\n",
              "      <td>-0.2187</td>\n",
              "      <td>-1.4080</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_0015fd391</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>48</td>\n",
              "      <td>D1</td>\n",
              "      <td>8c7f86626</td>\n",
              "      <td>-0.5138</td>\n",
              "      <td>-0.2491</td>\n",
              "      <td>-0.2656</td>\n",
              "      <td>0.5288</td>\n",
              "      <td>4.0620</td>\n",
              "      <td>-0.8095</td>\n",
              "      <td>-1.9590</td>\n",
              "      <td>0.1792</td>\n",
              "      <td>-0.1321</td>\n",
              "      <td>-1.0600</td>\n",
              "      <td>-0.8269</td>\n",
              "      <td>-0.3584</td>\n",
              "      <td>-0.8511</td>\n",
              "      <td>-0.5844</td>\n",
              "      <td>-2.5690</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>-0.0532</td>\n",
              "      <td>-0.8554</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>-2.3520</td>\n",
              "      <td>2.1200</td>\n",
              "      <td>-1.1580</td>\n",
              "      <td>-0.7191</td>\n",
              "      <td>-0.8004</td>\n",
              "      <td>-1.4670</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>-0.8995</td>\n",
              "      <td>0.2406</td>\n",
              "      <td>-0.2479</td>\n",
              "      <td>-1.0890</td>\n",
              "      <td>-0.7575</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>-2.7370</td>\n",
              "      <td>0.8745</td>\n",
              "      <td>0.5787</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.3820</td>\n",
              "      <td>-3.7350</td>\n",
              "      <td>-2.9740</td>\n",
              "      <td>-1.4930</td>\n",
              "      <td>-1.6600</td>\n",
              "      <td>-3.1660</td>\n",
              "      <td>0.2816</td>\n",
              "      <td>-0.2990</td>\n",
              "      <td>-1.1870</td>\n",
              "      <td>-0.5044</td>\n",
              "      <td>-1.7750</td>\n",
              "      <td>-1.6120</td>\n",
              "      <td>-0.9215</td>\n",
              "      <td>-1.0810</td>\n",
              "      <td>-3.0520</td>\n",
              "      <td>-3.4470</td>\n",
              "      <td>-2.7740</td>\n",
              "      <td>-1.8460</td>\n",
              "      <td>-0.5568</td>\n",
              "      <td>-3.3960</td>\n",
              "      <td>-2.9510</td>\n",
              "      <td>-1.1550</td>\n",
              "      <td>-3.2620</td>\n",
              "      <td>-1.5390</td>\n",
              "      <td>-2.4600</td>\n",
              "      <td>-0.9417</td>\n",
              "      <td>-1.5550</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>-2.0990</td>\n",
              "      <td>-0.6441</td>\n",
              "      <td>-5.6300</td>\n",
              "      <td>-1.3780</td>\n",
              "      <td>-0.8632</td>\n",
              "      <td>-1.2880</td>\n",
              "      <td>-1.6210</td>\n",
              "      <td>-0.8784</td>\n",
              "      <td>-0.3876</td>\n",
              "      <td>-0.8154</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_001626bd3</td>\n",
              "      <td>com_droga</td>\n",
              "      <td>72</td>\n",
              "      <td>D2</td>\n",
              "      <td>7cbed3131</td>\n",
              "      <td>-0.3254</td>\n",
              "      <td>-0.4009</td>\n",
              "      <td>0.9700</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>1.4180</td>\n",
              "      <td>-0.8244</td>\n",
              "      <td>-0.2800</td>\n",
              "      <td>-0.1498</td>\n",
              "      <td>-0.8789</td>\n",
              "      <td>0.8630</td>\n",
              "      <td>-0.2219</td>\n",
              "      <td>-0.5121</td>\n",
              "      <td>-0.9577</td>\n",
              "      <td>1.1750</td>\n",
              "      <td>0.2042</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1244</td>\n",
              "      <td>-1.7090</td>\n",
              "      <td>-0.3543</td>\n",
              "      <td>-0.5160</td>\n",
              "      <td>-0.3330</td>\n",
              "      <td>-0.2685</td>\n",
              "      <td>0.7649</td>\n",
              "      <td>0.2057</td>\n",
              "      <td>1.3720</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.8056</td>\n",
              "      <td>-0.3754</td>\n",
              "      <td>-1.2090</td>\n",
              "      <td>0.2965</td>\n",
              "      <td>-0.0712</td>\n",
              "      <td>0.6389</td>\n",
              "      <td>0.6674</td>\n",
              "      <td>-0.0783</td>\n",
              "      <td>1.1740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1535</td>\n",
              "      <td>-0.4640</td>\n",
              "      <td>-0.5943</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.5159</td>\n",
              "      <td>0.6091</td>\n",
              "      <td>0.1813</td>\n",
              "      <td>-0.4249</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5648</td>\n",
              "      <td>0.4817</td>\n",
              "      <td>0.0587</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.6376</td>\n",
              "      <td>-0.3966</td>\n",
              "      <td>-1.4950</td>\n",
              "      <td>-0.9625</td>\n",
              "      <td>-0.0541</td>\n",
              "      <td>0.6273</td>\n",
              "      <td>0.4563</td>\n",
              "      <td>0.0698</td>\n",
              "      <td>0.8134</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.6054</td>\n",
              "      <td>-0.1824</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.6670</td>\n",
              "      <td>1.0690</td>\n",
              "      <td>0.5523</td>\n",
              "      <td>-0.3031</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.2885</td>\n",
              "      <td>-0.3786</td>\n",
              "      <td>0.7125</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 879 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id tratamento  tempo dose  ...    c-98    c-99  n_moa  ativo_moa\n",
              "0  id_000644bb2  com_droga     24   D1  ...  0.3801  0.4176      1       True\n",
              "1  id_000779bfc  com_droga     72   D1  ...  0.6077  0.7371      0      False\n",
              "2  id_000a6266a  com_droga     48   D1  ... -1.4080  0.6931      3       True\n",
              "3  id_0015fd391  com_droga     48   D1  ... -0.3876 -0.8154      0      False\n",
              "4  id_001626bd3  com_droga     72   D2  ... -0.3786  0.7125      1       True\n",
              "\n",
              "[5 rows x 879 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJbEhnWRMeZL"
      },
      "source": [
        "### Objetivo:\n",
        "\n",
        "Com esses dados podemos tentar prever algumas informações, como por exemplo qual tipo de ativação poderá ocorrer para uma determinada assinatura de experimento, para o nosso trabalho vamos tentar prever o número de ativações para uma dada assinatura, ou seja, utilizando os dados do DataFrame, tabela dados_experimentos queremos prever a coluna n_moa do DataFrame, tabela dados_resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8ioyvphwwLq"
      },
      "source": [
        "## Correlação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhvqLIbKwzEW"
      },
      "source": [
        "Antes de partimos para a modelagem podemos tentar entender um pouco melhor nossos dados, sobre tudo as correlações entre colunas com a coluna que queremos prever n_moa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLtwyx3WxClD",
        "outputId": "2e3fc553-fd8f-4c11-9134-e7697653b750"
      },
      "source": [
        "# Selecionando as colunas numéricas\n",
        "features = dados_combinados.select_dtypes('float64').columns\n",
        "features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['g-0', 'g-1', 'g-2', 'g-3', 'g-4', 'g-5', 'g-6', 'g-7', 'g-8', 'g-9',\n",
              "       ...\n",
              "       'c-90', 'c-91', 'c-92', 'c-93', 'c-94', 'c-95', 'c-96', 'c-97', 'c-98',\n",
              "       'c-99'],\n",
              "      dtype='object', length=872)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyYYlJYiw89x",
        "outputId": "58be412c-036e-41d0-b4fa-a6adfc927825"
      },
      "source": [
        "correlation = dados_combinados[features].corrwith(dados_combinados.n_moa).sort_values(axis=0, ascending=False)\n",
        "print(correlation)\n",
        "print(type(dados_combinados[features].corrwith(dados_combinados.n_moa)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "g-100    0.296536\n",
            "g-731    0.290808\n",
            "g-349    0.287637\n",
            "g-201    0.272311\n",
            "g-460    0.270822\n",
            "           ...   \n",
            "c-83    -0.297759\n",
            "c-78    -0.302613\n",
            "c-17    -0.304955\n",
            "c-98    -0.321354\n",
            "c-65    -0.321906\n",
            "Length: 872, dtype: float64\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVZJmn5JxKIy"
      },
      "source": [
        "Com as informações acima podemos ver que algumas informações de genes como g-100, g-731 e g-349 possuem uma correlação mais positiva com o valor que queremos prever e as informações c-65, c-98, c17 possuem uma correlação negativa, por tanto são colunas importantes na hora de prever o nosso resultado esperado. Podemos tentar montar um modelo futuramente apenas utilizando as features com correlações positivas e negativas que sejam mais altas. Podemos ainda averiguar a correlação entre as colunas para cada coluna de nosso dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "jVqrtNzrw_4x",
        "outputId": "0c5d3ea9-e660-44bf-cbe1-92257ef92f3d"
      },
      "source": [
        "corr = dados_combinados[['g-100', 'g-731', 'g-349', 'c-65', 'c-98', 'c-17', 'n_moa']].corr().abs()\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g-100</th>\n",
              "      <th>g-731</th>\n",
              "      <th>g-349</th>\n",
              "      <th>c-65</th>\n",
              "      <th>c-98</th>\n",
              "      <th>c-17</th>\n",
              "      <th>n_moa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>g-100</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.726355</td>\n",
              "      <td>0.640477</td>\n",
              "      <td>0.702329</td>\n",
              "      <td>0.685872</td>\n",
              "      <td>0.681764</td>\n",
              "      <td>0.296536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>g-731</th>\n",
              "      <td>0.726355</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.794807</td>\n",
              "      <td>0.814306</td>\n",
              "      <td>0.786722</td>\n",
              "      <td>0.792886</td>\n",
              "      <td>0.290808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>g-349</th>\n",
              "      <td>0.640477</td>\n",
              "      <td>0.794807</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.801896</td>\n",
              "      <td>0.762771</td>\n",
              "      <td>0.834119</td>\n",
              "      <td>0.287637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c-65</th>\n",
              "      <td>0.702329</td>\n",
              "      <td>0.814306</td>\n",
              "      <td>0.801896</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.885875</td>\n",
              "      <td>0.869226</td>\n",
              "      <td>0.321906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c-98</th>\n",
              "      <td>0.685872</td>\n",
              "      <td>0.786722</td>\n",
              "      <td>0.762771</td>\n",
              "      <td>0.885875</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.832252</td>\n",
              "      <td>0.321354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c-17</th>\n",
              "      <td>0.681764</td>\n",
              "      <td>0.792886</td>\n",
              "      <td>0.834119</td>\n",
              "      <td>0.869226</td>\n",
              "      <td>0.832252</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.304955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_moa</th>\n",
              "      <td>0.296536</td>\n",
              "      <td>0.290808</td>\n",
              "      <td>0.287637</td>\n",
              "      <td>0.321906</td>\n",
              "      <td>0.321354</td>\n",
              "      <td>0.304955</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          g-100     g-731     g-349      c-65      c-98      c-17     n_moa\n",
              "g-100  1.000000  0.726355  0.640477  0.702329  0.685872  0.681764  0.296536\n",
              "g-731  0.726355  1.000000  0.794807  0.814306  0.786722  0.792886  0.290808\n",
              "g-349  0.640477  0.794807  1.000000  0.801896  0.762771  0.834119  0.287637\n",
              "c-65   0.702329  0.814306  0.801896  1.000000  0.885875  0.869226  0.321906\n",
              "c-98   0.685872  0.786722  0.762771  0.885875  1.000000  0.832252  0.321354\n",
              "c-17   0.681764  0.792886  0.834119  0.869226  0.832252  1.000000  0.304955\n",
              "n_moa  0.296536  0.290808  0.287637  0.321906  0.321354  0.304955  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "WRdY4KbwyANl",
        "outputId": "d1be2e64-43f2-422d-e6ec-e5a8bf74539d"
      },
      "source": [
        "## correlation \n",
        "\n",
        "import plotly.figure_factory as ff\n",
        "primary_bgcolor = \"#f4f0ea\"\n",
        "\n",
        "corr = corr\n",
        "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "corr1 = corr.mask(mask)\n",
        "\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z=corr1.to_numpy().round(2),\n",
        "    x=list(corr1.index.values),\n",
        "    y=list(corr1.columns.values),       \n",
        "    xgap=3, ygap=3,\n",
        "    zmin=0, zmax=1,\n",
        "    colorscale='blugrn',\n",
        "    colorbar_thickness=30,\n",
        "    colorbar_ticklen=3,\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='<span style=\"font-size:32px; font-family:Times New Roman\">Features Correlation Matrix</span>', \n",
        "    font_family=\"Serif\",\n",
        "    titlefont={'size': 24},\n",
        "    width=800, height=700,\n",
        "    xaxis_showgrid=False,\n",
        "    yaxis_showgrid=False,\n",
        "    yaxis_autorange='reversed', \n",
        "    paper_bgcolor=primary_bgcolor,\n",
        "    plot_bgcolor=primary_bgcolor,\n",
        "    margin=dict(l=70, r=70, t=70, b=70, pad=1),\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"60d18a52-4374-4f29-8a83-720772ead398\" class=\"plotly-graph-div\" style=\"height:700px; width:800px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"60d18a52-4374-4f29-8a83-720772ead398\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '60d18a52-4374-4f29-8a83-720772ead398',\n",
              "                        [{\"colorbar\": {\"thickness\": 30, \"ticklen\": 3}, \"colorscale\": [[0.0, \"rgb(196, 230, 195)\"], [0.16666666666666666, \"rgb(150, 210, 164)\"], [0.3333333333333333, \"rgb(109, 188, 144)\"], [0.5, \"rgb(77, 162, 132)\"], [0.6666666666666666, \"rgb(54, 135, 122)\"], [0.8333333333333334, \"rgb(38, 107, 110)\"], [1.0, \"rgb(29, 79, 96)\"]], \"reversescale\": false, \"showscale\": false, \"type\": \"heatmap\", \"x\": [\"g-100\", \"g-731\", \"g-349\", \"c-65\", \"c-98\", \"c-17\", \"n_moa\"], \"xgap\": 3, \"y\": [\"g-100\", \"g-731\", \"g-349\", \"c-65\", \"c-98\", \"c-17\", \"n_moa\"], \"ygap\": 3, \"z\": [[null, null, null, null, null, null, null], [0.73, null, null, null, null, null, null], [0.64, 0.79, null, null, null, null, null], [0.7, 0.81, 0.8, null, null, null, null], [0.69, 0.79, 0.76, 0.89, null, null, null], [0.68, 0.79, 0.83, 0.87, 0.83, null, null], [0.3, 0.29, 0.29, 0.32, 0.32, 0.3, null]], \"zmax\": 1, \"zmin\": 0}],\n",
              "                        {\"annotations\": [{\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"g-100\", \"xref\": \"x\", \"y\": \"g-100\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"g-731\", \"xref\": \"x\", \"y\": \"g-100\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"g-349\", \"xref\": \"x\", \"y\": \"g-100\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-65\", \"xref\": \"x\", \"y\": \"g-100\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-98\", \"xref\": \"x\", \"y\": \"g-100\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-17\", \"xref\": \"x\", \"y\": \"g-100\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"n_moa\", \"xref\": \"x\", \"y\": \"g-100\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.73\", \"x\": \"g-100\", \"xref\": \"x\", \"y\": \"g-731\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"g-731\", \"xref\": \"x\", \"y\": \"g-731\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"g-349\", \"xref\": \"x\", \"y\": \"g-731\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-65\", \"xref\": \"x\", \"y\": \"g-731\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-98\", \"xref\": \"x\", \"y\": \"g-731\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-17\", \"xref\": \"x\", \"y\": \"g-731\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"n_moa\", \"xref\": \"x\", \"y\": \"g-731\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.64\", \"x\": \"g-100\", \"xref\": \"x\", \"y\": \"g-349\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.79\", \"x\": \"g-731\", \"xref\": \"x\", \"y\": \"g-349\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"g-349\", \"xref\": \"x\", \"y\": \"g-349\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-65\", \"xref\": \"x\", \"y\": \"g-349\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-98\", \"xref\": \"x\", \"y\": \"g-349\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-17\", \"xref\": \"x\", \"y\": \"g-349\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"n_moa\", \"xref\": \"x\", \"y\": \"g-349\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.7\", \"x\": \"g-100\", \"xref\": \"x\", \"y\": \"c-65\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.81\", \"x\": \"g-731\", \"xref\": \"x\", \"y\": \"c-65\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.8\", \"x\": \"g-349\", \"xref\": \"x\", \"y\": \"c-65\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-65\", \"xref\": \"x\", \"y\": \"c-65\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-98\", \"xref\": \"x\", \"y\": \"c-65\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-17\", \"xref\": \"x\", \"y\": \"c-65\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"n_moa\", \"xref\": \"x\", \"y\": \"c-65\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.69\", \"x\": \"g-100\", \"xref\": \"x\", \"y\": \"c-98\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.79\", \"x\": \"g-731\", \"xref\": \"x\", \"y\": \"c-98\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.76\", \"x\": \"g-349\", \"xref\": \"x\", \"y\": \"c-98\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.89\", \"x\": \"c-65\", \"xref\": \"x\", \"y\": \"c-98\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-98\", \"xref\": \"x\", \"y\": \"c-98\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-17\", \"xref\": \"x\", \"y\": \"c-98\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"n_moa\", \"xref\": \"x\", \"y\": \"c-98\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.68\", \"x\": \"g-100\", \"xref\": \"x\", \"y\": \"c-17\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.79\", \"x\": \"g-731\", \"xref\": \"x\", \"y\": \"c-17\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.83\", \"x\": \"g-349\", \"xref\": \"x\", \"y\": \"c-17\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.87\", \"x\": \"c-65\", \"xref\": \"x\", \"y\": \"c-17\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.83\", \"x\": \"c-98\", \"xref\": \"x\", \"y\": \"c-17\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"c-17\", \"xref\": \"x\", \"y\": \"c-17\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"n_moa\", \"xref\": \"x\", \"y\": \"c-17\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.3\", \"x\": \"g-100\", \"xref\": \"x\", \"y\": \"n_moa\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.29\", \"x\": \"g-731\", \"xref\": \"x\", \"y\": \"n_moa\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.29\", \"x\": \"g-349\", \"xref\": \"x\", \"y\": \"n_moa\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.32\", \"x\": \"c-65\", \"xref\": \"x\", \"y\": \"n_moa\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.32\", \"x\": \"c-98\", \"xref\": \"x\", \"y\": \"n_moa\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"0.3\", \"x\": \"c-17\", \"xref\": \"x\", \"y\": \"n_moa\", \"yref\": \"y\"}, {\"font\": {\"color\": \"#FFFFFF\"}, \"showarrow\": false, \"text\": \"nan\", \"x\": \"n_moa\", \"xref\": \"x\", \"y\": \"n_moa\", \"yref\": \"y\"}], \"font\": {\"family\": \"Serif\"}, \"height\": 700, \"margin\": {\"b\": 70, \"l\": 70, \"pad\": 1, \"r\": 70, \"t\": 70}, \"paper_bgcolor\": \"#f4f0ea\", \"plot_bgcolor\": \"#f4f0ea\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"size\": 24}, \"text\": \"<span style=\\\"font-size:32px; font-family:Times New Roman\\\">Features Correlation Matrix</span>\"}, \"width\": 800, \"xaxis\": {\"dtick\": 1, \"gridcolor\": \"rgb(0, 0, 0)\", \"showgrid\": false, \"side\": \"top\", \"ticks\": \"\"}, \"yaxis\": {\"autorange\": \"reversed\", \"dtick\": 1, \"showgrid\": false, \"ticks\": \"\", \"ticksuffix\": \"  \"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('60d18a52-4374-4f29-8a83-720772ead398');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "walAm1H0uEVd"
      },
      "source": [
        "## Antes de montarmos nosso modelo vamos plotar a distribuição das nossas classes de ativação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1D3xMTKNTqib",
        "outputId": "0e4f8ff6-83cb-4007-97a9-525f0f17a88b"
      },
      "source": [
        "# Histogram \n",
        "sns.distplot(a=dados_combinados['n_moa'], kde=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff0e870b490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "DSOtADTluL_-",
        "outputId": "7f22898f-0bd0-4607-f59c-4162c42fc0bb"
      },
      "source": [
        "# KDE plot kernel density estimat\n",
        "sns.kdeplot(data=dados_combinados['n_moa'], shade=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff0e7b64110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9bK4pwuuPs1"
      },
      "source": [
        "Podemos ver que nossos dados não são muito bem distruibuidos, ou seja, não seguem uma distribuição normal e são altamente concentrados entre as os números 0 e 1, portanto é bem provável que nossos modelos irão erra muito prevendo classes que deveriam ser entre 2 a 7, como sendo algo entre 0 e 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUmlg3YTTrWF"
      },
      "source": [
        "### Vamos primeiro transformar nossas variáveis categóricas em colunas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOel8fHLTzml"
      },
      "source": [
        "x = dados_combinados.drop(['id', 'n_moa', 'ativo_moa', 'droga'], axis=1)\n",
        "x = pd.get_dummies(x, columns=['tratamento', 'dose', 'tempo'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUAWPZUBMeZO"
      },
      "source": [
        "### Agora vamos separar nossos dados em uma base de treino e de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5jVV1v4MeZO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = dados_combinados['n_moa'] \n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = 0.2, stratify=y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSKokOySMeZP"
      },
      "source": [
        "#### Para a nossa previssão vamos experimentar 3 algoritmos: RandomForestRegressor, ExtraTreesRegressor e DecisionTreeRegressor afim de validarmos como três modelos baseados em uma hierarquia de decisão em árvore irão se comportar e vamos utilizar o GridSearchCV do sklearn para tunar os modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAPw8xGyMeZP"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmWJiXOXMeZQ"
      },
      "source": [
        "### Parâmetros que queremos tunar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8UbHpv0MeZQ"
      },
      "source": [
        "# parameters_rfr = {'criterion': ('mse', 'mae'), 'n_estimators':[100, 200, 400], 'max_depth': [None, 5, 10, 15]}\n",
        "parameters_rfr = {'n_estimators':[100, 400], 'max_depth': (None, 5, 15)}\n",
        "# parameters_dtr = {'criterion': ('mse', 'mae'), 'splitter': ('best', 'random'), 'max_depth': [None, 5, 10, 15]}\n",
        "parameters_dtr = {'splitter': ('best', 'random'), 'max_depth': [None, 5, 10, 15]}\n",
        "#parameters_etr = {'n_estimators':[100, 200, 400], 'max_depth': [None, 5, 10, 15], 'criterion': ('gini', 'entropy')}\n",
        "parameters_etr = {'n_estimators':[100, 400], 'max_depth': [None, 5, 15]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zakjjastMeZQ"
      },
      "source": [
        "### Instanciando os modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjuwBgO6MeZR"
      },
      "source": [
        "rfr = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
        "etr = ExtraTreesClassifier(verbose=1, n_jobs=-1)\n",
        "dtr = DecisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wte7bqtjMeZR"
      },
      "source": [
        "### Passando os parâmetros para o GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAhn5zjrMeZR"
      },
      "source": [
        "rfr = GridSearchCV(rfr, parameters_rfr, verbose=3)\n",
        "etr = GridSearchCV(etr, parameters_etr, verbose=3)\n",
        "dtr = GridSearchCV(dtr, parameters_dtr, verbose=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmebEb1WMeZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526fc32d-11a4-4ba0-a0b8-cf5308057f8a"
      },
      "source": [
        "rfr.fit(x_treino, y_treino)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.2s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   44.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   44.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.632, total=  44.9s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   20.1s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   43.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.5min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.631, total=  43.5s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   20.0s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   42.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.630, total=  43.2s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   20.1s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   43.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.633, total=  44.2s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   20.2s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   42.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.632, total=  43.3s\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   19.8s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.9min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.640, total= 2.9min\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   19.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.8min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.644, total= 2.8min\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   20.1s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.9min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.638, total= 2.9min\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   20.0s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.9min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.648, total= 2.9min\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   19.9s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.8min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.640, total= 2.8min\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.4s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.637, total=  12.7s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.641, total=  12.8s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.639, total=  12.6s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.642, total=  12.7s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.638, total=  12.6s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   24.1s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   49.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.638, total=  49.6s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   24.1s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   49.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.641, total=  49.5s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   24.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   48.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.639, total=  49.4s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   24.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   48.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.642, total=  49.5s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   23.8s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   48.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.639, total=  49.3s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.6s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.637, total=  31.9s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.6s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.644, total=  31.8s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   30.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.638, total=  31.3s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.648, total=  31.6s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.638, total=  31.3s\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.639, total= 2.1min\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.643, total= 2.1min\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.640, total= 2.1min\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.645, total= 2.1min\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  2.1min finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 36.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.642, total= 2.1min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   25.1s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  3.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=-1,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=1,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': (None, 5, 15),\n",
              "                         'n_estimators': [100, 400]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pBmoLREMeZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7946141-74d5-456d-d5d5-625d8038249f"
      },
      "source": [
        "etr.fit(x_treino, y_treino)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.638, total=  10.2s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   20.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.636, total=  10.0s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.636, total=  10.3s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.640, total=  10.1s\n",
            "[CV] max_depth=None, n_estimators=100 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=100, score=0.636, total=  10.0s\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   19.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   38.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.641, total=  39.7s\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   18.8s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   38.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.645, total=  39.1s\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   19.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   38.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.641, total=  39.7s\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   18.9s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   38.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.647, total=  39.4s\n",
            "[CV] max_depth=None, n_estimators=400 ................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   18.9s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   38.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... max_depth=None, n_estimators=400, score=0.644, total=  39.3s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.635, total=   1.4s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.640, total=   1.4s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.634, total=   1.4s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.638, total=   1.4s\n",
            "[CV] max_depth=5, n_estimators=100 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=100, score=0.634, total=   1.4s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    4.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.636, total=   4.5s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    4.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.640, total=   4.6s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    4.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.635, total=   4.5s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    4.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.638, total=   4.5s\n",
            "[CV] max_depth=5, n_estimators=400 ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    4.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=5, n_estimators=400, score=0.636, total=   4.5s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.639, total=   3.9s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.645, total=   4.0s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.640, total=   3.9s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.646, total=   4.0s\n",
            "[CV] max_depth=15, n_estimators=100 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=100, score=0.643, total=   3.9s\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   13.7s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   14.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.640, total=  14.8s\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   14.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.644, total=  14.8s\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   13.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.640, total=  14.3s\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   13.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.645, total=  14.4s\n",
            "[CV] max_depth=15, n_estimators=400 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   14.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  6.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ...... max_depth=15, n_estimators=400, score=0.643, total=  14.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   23.0s\n",
            "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   46.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
              "                                            class_weight=None, criterion='gini',\n",
              "                                            max_depth=None, max_features='auto',\n",
              "                                            max_leaf_nodes=None,\n",
              "                                            max_samples=None,\n",
              "                                            min_impurity_decrease=0.0,\n",
              "                                            min_impurity_split=None,\n",
              "                                            min_samples_leaf=1,\n",
              "                                            min_samples_split=2,\n",
              "                                            min_weight_fraction_leaf=0.0,\n",
              "                                            n_estimators=100, n_jobs=-1,\n",
              "                                            oob_score=False, random_state=None,\n",
              "                                            verbose=1, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [None, 5, 15],\n",
              "                         'n_estimators': [100, 400]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN4MQ2zTMeZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5004a4f-350e-4433-f519-544320f78cde"
      },
      "source": [
        "dtr.fit(x_treino, y_treino)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "[CV] max_depth=None, splitter=best ...................................\n",
            "[CV] ....... max_depth=None, splitter=best, score=0.539, total=  28.5s\n",
            "[CV] max_depth=None, splitter=best ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   28.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=None, splitter=best, score=0.544, total=  31.6s\n",
            "[CV] max_depth=None, splitter=best ...................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ....... max_depth=None, splitter=best, score=0.555, total=  30.2s\n",
            "[CV] max_depth=None, splitter=best ...................................\n",
            "[CV] ....... max_depth=None, splitter=best, score=0.565, total=  27.6s\n",
            "[CV] max_depth=None, splitter=best ...................................\n",
            "[CV] ....... max_depth=None, splitter=best, score=0.541, total=  30.3s\n",
            "[CV] max_depth=None, splitter=random .................................\n",
            "[CV] ..... max_depth=None, splitter=random, score=0.530, total=   2.1s\n",
            "[CV] max_depth=None, splitter=random .................................\n",
            "[CV] ..... max_depth=None, splitter=random, score=0.559, total=   2.2s\n",
            "[CV] max_depth=None, splitter=random .................................\n",
            "[CV] ..... max_depth=None, splitter=random, score=0.544, total=   2.0s\n",
            "[CV] max_depth=None, splitter=random .................................\n",
            "[CV] ..... max_depth=None, splitter=random, score=0.554, total=   2.2s\n",
            "[CV] max_depth=None, splitter=random .................................\n",
            "[CV] ..... max_depth=None, splitter=random, score=0.552, total=   2.0s\n",
            "[CV] max_depth=5, splitter=best ......................................\n",
            "[CV] .......... max_depth=5, splitter=best, score=0.637, total=   7.5s\n",
            "[CV] max_depth=5, splitter=best ......................................\n",
            "[CV] .......... max_depth=5, splitter=best, score=0.637, total=   7.5s\n",
            "[CV] max_depth=5, splitter=best ......................................\n",
            "[CV] .......... max_depth=5, splitter=best, score=0.636, total=   7.5s\n",
            "[CV] max_depth=5, splitter=best ......................................\n",
            "[CV] .......... max_depth=5, splitter=best, score=0.640, total=   7.5s\n",
            "[CV] max_depth=5, splitter=best ......................................\n",
            "[CV] .......... max_depth=5, splitter=best, score=0.635, total=   7.5s\n",
            "[CV] max_depth=5, splitter=random ....................................\n",
            "[CV] ........ max_depth=5, splitter=random, score=0.634, total=   0.4s\n",
            "[CV] max_depth=5, splitter=random ....................................\n",
            "[CV] ........ max_depth=5, splitter=random, score=0.631, total=   0.4s\n",
            "[CV] max_depth=5, splitter=random ....................................\n",
            "[CV] ........ max_depth=5, splitter=random, score=0.636, total=   0.3s\n",
            "[CV] max_depth=5, splitter=random ....................................\n",
            "[CV] ........ max_depth=5, splitter=random, score=0.640, total=   0.4s\n",
            "[CV] max_depth=5, splitter=random ....................................\n",
            "[CV] ........ max_depth=5, splitter=random, score=0.634, total=   0.3s\n",
            "[CV] max_depth=10, splitter=best .....................................\n",
            "[CV] ......... max_depth=10, splitter=best, score=0.636, total=  14.3s\n",
            "[CV] max_depth=10, splitter=best .....................................\n",
            "[CV] ......... max_depth=10, splitter=best, score=0.638, total=  14.5s\n",
            "[CV] max_depth=10, splitter=best .....................................\n",
            "[CV] ......... max_depth=10, splitter=best, score=0.626, total=  14.4s\n",
            "[CV] max_depth=10, splitter=best .....................................\n",
            "[CV] ......... max_depth=10, splitter=best, score=0.640, total=  14.3s\n",
            "[CV] max_depth=10, splitter=best .....................................\n",
            "[CV] ......... max_depth=10, splitter=best, score=0.629, total=  14.4s\n",
            "[CV] max_depth=10, splitter=random ...................................\n",
            "[CV] ....... max_depth=10, splitter=random, score=0.634, total=   0.7s\n",
            "[CV] max_depth=10, splitter=random ...................................\n",
            "[CV] ....... max_depth=10, splitter=random, score=0.637, total=   0.7s\n",
            "[CV] max_depth=10, splitter=random ...................................\n",
            "[CV] ....... max_depth=10, splitter=random, score=0.624, total=   0.8s\n",
            "[CV] max_depth=10, splitter=random ...................................\n",
            "[CV] ....... max_depth=10, splitter=random, score=0.638, total=   0.7s\n",
            "[CV] max_depth=10, splitter=random ...................................\n",
            "[CV] ....... max_depth=10, splitter=random, score=0.636, total=   0.6s\n",
            "[CV] max_depth=15, splitter=best .....................................\n",
            "[CV] ......... max_depth=15, splitter=best, score=0.602, total=  20.0s\n",
            "[CV] max_depth=15, splitter=best .....................................\n",
            "[CV] ......... max_depth=15, splitter=best, score=0.614, total=  20.5s\n",
            "[CV] max_depth=15, splitter=best .....................................\n",
            "[CV] ......... max_depth=15, splitter=best, score=0.601, total=  20.2s\n",
            "[CV] max_depth=15, splitter=best .....................................\n",
            "[CV] ......... max_depth=15, splitter=best, score=0.594, total=  19.9s\n",
            "[CV] max_depth=15, splitter=best .....................................\n",
            "[CV] ......... max_depth=15, splitter=best, score=0.609, total=  20.2s\n",
            "[CV] max_depth=15, splitter=random ...................................\n",
            "[CV] ....... max_depth=15, splitter=random, score=0.619, total=   1.0s\n",
            "[CV] max_depth=15, splitter=random ...................................\n",
            "[CV] ....... max_depth=15, splitter=random, score=0.616, total=   1.1s\n",
            "[CV] max_depth=15, splitter=random ...................................\n",
            "[CV] ....... max_depth=15, splitter=random, score=0.614, total=   1.0s\n",
            "[CV] max_depth=15, splitter=random ...................................\n",
            "[CV] ....... max_depth=15, splitter=random, score=0.625, total=   1.0s\n",
            "[CV] max_depth=15, splitter=random ...................................\n",
            "[CV] ....... max_depth=15, splitter=random, score=0.609, total=   1.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  6.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [None, 5, 10, 15],\n",
              "                         'splitter': ('best', 'random')},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "Ol18GJFEpJiI",
        "outputId": "ffd0cb3f-df79-4e6d-9a03-d7d9842da403"
      },
      "source": [
        "'''\n",
        "GridSearchCV(cv=None, error_score=nan,\n",
        "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
        "                                              class_weight=None,\n",
        "                                              criterion='gini', max_depth=None,\n",
        "                                              max_features='auto',\n",
        "                                              max_leaf_nodes=None,\n",
        "                                              max_samples=None,\n",
        "                                              min_impurity_decrease=0.0,\n",
        "                                              min_impurity_split=None,\n",
        "                                              min_samples_leaf=1,\n",
        "                                              min_samples_split=2,\n",
        "                                              min_weight_fraction_leaf=0.0,\n",
        "                                              n_estimators=100, n_jobs=-1,\n",
        "                                              oob_score=False,\n",
        "                                              random_state=None, verbose=1,\n",
        "                                              warm_start=False),\n",
        "             iid='deprecated', n_jobs=None,\n",
        "             param_grid={'max_depth': (None, 5, 15),\n",
        "                         'n_estimators': [100, 400]},\n",
        "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
        "             scoring=None, verbose=3)\n",
        "\n",
        "GridSearchCV(cv=None, error_score=nan,\n",
        "             estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
        "                                            class_weight=None, criterion='gini',\n",
        "                                            max_depth=None, max_features='auto',\n",
        "                                            max_leaf_nodes=None,\n",
        "                                            max_samples=None,\n",
        "                                            min_impurity_decrease=0.0,\n",
        "                                            min_impurity_split=None,\n",
        "                                            min_samples_leaf=1,\n",
        "                                            min_samples_split=2,\n",
        "                                            min_weight_fraction_leaf=0.0,\n",
        "                                            n_estimators=100, n_jobs=-1,\n",
        "                                            oob_score=False, random_state=None,\n",
        "                                            verbose=1, warm_start=False),\n",
        "             iid='deprecated', n_jobs=None,\n",
        "             param_grid={'max_depth': [None, 5, 15],\n",
        "                         'n_estimators': [100, 400]},\n",
        "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
        "             scoring=None, verbose=3)\n",
        "\n",
        "             GridSearchCV(cv=None, error_score=nan,\n",
        "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
        "                                              criterion='gini', max_depth=None,\n",
        "                                              max_features=None,\n",
        "                                              max_leaf_nodes=None,\n",
        "                                              min_impurity_decrease=0.0,\n",
        "                                              min_impurity_split=None,\n",
        "                                              min_samples_leaf=1,\n",
        "                                              min_samples_split=2,\n",
        "                                              min_weight_fraction_leaf=0.0,\n",
        "                                              presort='deprecated',\n",
        "                                              random_state=None,\n",
        "                                              splitter='best'),\n",
        "             iid='deprecated', n_jobs=None,\n",
        "             param_grid={'max_depth': [None, 5, 10, 15],\n",
        "                         'splitter': ('best', 'random')},\n",
        "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
        "             scoring=None, verbose=3)\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nGridSearchCV(cv=None, error_score=nan,\\n             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\\n                                              class_weight=None,\\n                                              criterion='gini', max_depth=None,\\n                                              max_features='auto',\\n                                              max_leaf_nodes=None,\\n                                              max_samples=None,\\n                                              min_impurity_decrease=0.0,\\n                                              min_impurity_split=None,\\n                                              min_samples_leaf=1,\\n                                              min_samples_split=2,\\n                                              min_weight_fraction_leaf=0.0,\\n                                              n_estimators=100, n_jobs=-1,\\n                                              oob_score=False,\\n                                              random_state=None, verbose=1,\\n                                              warm_start=False),\\n             iid='deprecated', n_jobs=None,\\n             param_grid={'max_depth': (None, 5, 15),\\n                         'n_estimators': [100, 400]},\\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\\n             scoring=None, verbose=3)\\n\\nGridSearchCV(cv=None, error_score=nan,\\n             estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\\n                                            class_weight=None, criterion='gini',\\n                                            max_depth=None, max_features='auto',\\n                                            max_leaf_nodes=None,\\n                                            max_samples=None,\\n                                            min_impurity_decrease=0.0,\\n                                            min_impurity_split=None,\\n                                            min_samples_leaf=1,\\n                                            min_samples_split=2,\\n                                            min_weight_fraction_leaf=0.0,\\n                                            n_estimators=100, n_jobs=-1,\\n                                            oob_score=False, random_state=None,\\n                                            verbose=1, warm_start=False),\\n             iid='deprecated', n_jobs=None,\\n             param_grid={'max_depth': [None, 5, 15],\\n                         'n_estimators': [100, 400]},\\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\\n             scoring=None, verbose=3)\\n\\n             GridSearchCV(cv=None, error_score=nan,\\n             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\\n                                              criterion='gini', max_depth=None,\\n                                              max_features=None,\\n                                              max_leaf_nodes=None,\\n                                              min_impurity_decrease=0.0,\\n                                              min_impurity_split=None,\\n                                              min_samples_leaf=1,\\n                                              min_samples_split=2,\\n                                              min_weight_fraction_leaf=0.0,\\n                                              presort='deprecated',\\n                                              random_state=None,\\n                                              splitter='best'),\\n             iid='deprecated', n_jobs=None,\\n             param_grid={'max_depth': [None, 5, 10, 15],\\n                         'splitter': ('best', 'random')},\\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\\n             scoring=None, verbose=3)\\n\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0EE-8k0MeZT"
      },
      "source": [
        "### Com os modelos treinados e tunados, vamos tentar prever os números de ativações para cada assinatura de experimento do nosso conjunto de testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM2h1s0QMeZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d7b0c3-9428-4844-e50b-6a9e1db0f3ae"
      },
      "source": [
        "rfr_predictions = rfr.predict(x_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZl9VHCCMeZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131f79c4-9075-4f6e-a3ea-797cc60cf788"
      },
      "source": [
        "etr_predictions = etr.predict(x_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jli7M0VMeZU"
      },
      "source": [
        "dtr_predictions = dtr.predict(x_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcF3007yMeZV"
      },
      "source": [
        "### Agora vamos avaliar a precisão do nossos modelos comparando os reultados das predições acima com os valores reais guardados em y_test, utilizando a função accuracy_score do sklearn para calcular a precisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GqNLzX_MeZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd557b14-12bd-4c9a-d41a-c886d4e1ccb1"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rfr_accuracy = accuracy_score(y_teste, rfr_predictions)\n",
        "etr_accuracy = accuracy_score(y_teste, etr_predictions)\n",
        "dtr_accuracy = accuracy_score(y_teste, dtr_predictions)\n",
        "\n",
        "print(\"A precisão do modelo RandomForestClassifier nos dados de teste é de: \" + str(rfr_accuracy))\n",
        "print(\"\\nA precisão do modelo ExtraTreesClassifier nos dados de teste é de: \" + str(etr_accuracy))\n",
        "print(\"\\nA precisão do modelo DecisionTreeClassifier nos dados de teste é de: \" + str(dtr_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A precisão do modelo RandomForestRegressor nos dados de teste é de: 0.6456015116523199\n",
            "\n",
            "A precisão do modelo ExtraTreesRegressor nos dados de teste é de: 0.6451816082301071\n",
            "\n",
            "A precisão do modelo DecisionTreeRegressor nos dados de teste é de: 0.6384631534747008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVwT0Ffqrc8j"
      },
      "source": [
        "Alcançamos um resultado muito semelhante entre os três modelos, mesmo tunando os parâmetros, logo podemos concluir que neste cenário o melhor modelo possa ser o modelo mais simples, DecisionTreeClassifier, uma vez que este perfomou muito próximo aos demais modelos mais complexos, como o ganho na precisão não é relevante e o tempo de treino dos modelos é, a escolha do DecisionTreeClassifier é interessante em cenários com pouco poder de processamento e pouco tempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDg_y5_tsG9A"
      },
      "source": [
        "### Para entendermos melhor como nosso modelo do DecisionTreeClassifier performa, podemos ver nossa matriz de confusão para saber onde estamos errando e acertando mais e posteriormente podemos tunar nosso modelo em busca de um modelo que erre mais uma classificação e acerte mais outras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Y9wM2YTcsF0J",
        "outputId": "a7b0ec08-7645-429f-d8ee-91d8cfdefb21"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = np.unique(y_teste)\n",
        "a = confusion_matrix(y_teste, dtr_predictions, labels=labels)\n",
        "pd.DataFrame(a, index=labels, columns=labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>415</td>\n",
              "      <td>1454</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>2487</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>162</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1    2  3  4  5  7\n",
              "0  415  1454    4  0  0  0  0\n",
              "1   13  2487    5  0  1  0  0\n",
              "2    6   162  139  0  1  0  0\n",
              "3    0    61    0  0  0  0  0\n",
              "4    0    11    0  0  0  0  0\n",
              "5    0     3    0  0  0  0  0\n",
              "7    0     0    1  0  0  0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxoNC7brtARH",
        "outputId": "969881b5-edfe-4db0-c345-e0922c8f9611"
      },
      "source": [
        "y_teste.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2506\n",
              "0    1873\n",
              "2     308\n",
              "3      61\n",
              "4      11\n",
              "5       3\n",
              "7       1\n",
              "Name: n_moa, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZdxmjT7uryv"
      },
      "source": [
        "## Conclusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ3eLbjxuwY7"
      },
      "source": [
        "Como esperado vimos que o modelo tende a predizer a maior parte das vezes um resultado entre as classes 0 e 1, tendendo mais fortemente a classificações na classe 1. Quando olhamos as assinaturas que deveriam ser previstas como 1, vimos que o modelo acerta 2487 de 2506, ou seja, errando apenas 19. Já para os números de ativações maior que 2, o modelo errou todas as predições."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGt945HcwBg_"
      },
      "source": [
        "Fica claro que uma das nossas maiores limitações é por conta do modelo altamente desbalanceado, para trabalhos futuros podemos tentar aplicar alguma forma de normalização em busca de uma distribuição mais normal ou aplicarmos algoritmos que sejam específicos para problemas de classes desbalançeadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OZPw2OMzogL"
      },
      "source": [
        "Além disso, podemos também posteriormente desenvolver modelos utilizando apenas as featues com correlação alta com a coluna que queremos predizer"
      ]
    }
  ]
}